\lstdefinestyle{bash}
{
    language=bash,
    extendedchars=true,
    keywordstyle=\bfseries,
    basicstyle=\footnotesize,
    frame=single,
    texcl=true
}
\lstdefinestyle{xml}
{
    language=xml,
    extendedchars=true,
    keywordstyle=\bfseries,
    basicstyle=\footnotesize,
    frame=single,
    tabsize=2,
    texcl=true
}
\newcommand\xml{{\it XML }}

\newpage
\section{Реализация предложенного подхода}
    % Какие функции выполняет приложение?
    % (Позволяет согласно описанному подходу прозводить семантический анализ
    % сообщений, а также измерять качество работы классификатора на основе описанных
    % оценочных метрик).
    Приложение предоставляет пользователю следующий набор возможностей:
    \begin{enumerate}
        \item Определение тональности сообщений тестовой коллекции по отношению к
        рассматриваемым компаниями. Для каждого сообщения тестовой коллекции,
        классификатор проставляет одну оценку из множества значений $\{1, 0, -1\}$;
        \item Составление собственной тестовой коллекции сообщений, по тематике
        схожих с отзывами о банках или телекоммуникационных компаниях
        (см. п. \ref{sec:tonalityCompetition}).
        \item Вычисление оценки работы классификатора на сообщениях тестовой
        коллекции с помощью сревнения полученных результатов с эталонными значениями.
        %В качестве оценок используются метрики качества $F_{macro}(neg, pos)$ и
        %$F_{micro}(neg, pos)$;
        \item Извлекать актуальные данные из сети \twitter с помощью
        {\it Streaming API}, а также набор инструментов для построения лексиконов
        на их основе.
    \end{enumerate}

    \subsection{Формат представления коллекций}
    % Здесь рассматриваются:
    %  -Формат данных, которые подаются на вход для проведения семантической
    % классификации. (XML)
    %  -Формат выходных данных (оценка качества работы классификатора
    %   (опциально), XML файл с просталвленными оценками)

    Изначально, для описания коллекций используется документ формата \xml, общая
    структура которого представлена в листинге \ref{lst:collectionExample}.
    Доукумент представляет собой экспорт таблицы с сообщениями
    из СУБД {\it MySQL}.
    Именно в таком формате, организаторы соревнований {\it SentiRuEval}
    распространяют все типы коллекций по каждой тематике.

    % Разбить на два участка кода
    \lstset{style=xml}
    \newpage
    \lstinputlisting[caption="Формат описания коллекций", label={lst:collectionExample}]{parts/code/collectionExample.xml}

    Все параметры сообщения можно разделить на два класса: {\it обязательные} и {\it дополнительные}.
    Каждое сообщение содержит следующий набор обязательных параметров:
    \begin{enumerate}
        \item {\tt id} --- идентификатор сообщения, уникальный в пределах рассматриваемой коллекции;
        \item {\tt twitid} --- уникальный идентификатор сообщения сети \twitter;
        \item {\tt date} --- дата появления сообщения в сети;
        \item {\tt text} --- текст сообщения.
    \end{enumerate}

    Набор дополнительных параметров зависит от предметной области, в которой рассматривается сообщение.
    В общем случае, это организации, по отношению к которым рассматривается сообщение.

    \subsection{Формат выходных данных}
    %
    % Выходные данные
    %
    Одним из результатов работы классификатора является \xml
    документ, формат которого совпадает с представлением описания коллекций \ref{...},
    содержащий идентификаторы тестовых сообщений коллекций с проставленными оценками.
    %Пример такого документа представлен в листинге \ref{lst:classifierResults}.
    %\lstset{style=xml}
    %\lstinputlisting[caption="Формат описания результатов классификатора.", label={lst:classifierResults}]{parts/code/classifierResults.xml}

    %В общем случае, результирующий документ
    %может исключать текст соответствующего сообщения и содержать только
    %идентифицирующую информацию. В данном случае текст сообщения присутствует
    %ввиду удобства просмотра результата.

    Оценка работы классификатора представлет собой текстовое сообщение,
    содержащее результаты показаний  $F_{macro}(neg, pos)$ и $F_{micro}(neg, pos)$,
    а также значения пераметров точности и полноты каждого тонального класса, на
    основе которых были вычислены результаты. Пример вывода результата
    качества работы классифкатора представлен в листинге \ref{lst:classifierScores}.

    \lstset{style=xml}
    \lstinputlisting[caption="Формат описания результатов классификатора.", label={lst:classifierScores}]{parts/code/classifierScores.xml}

    \subsection{Разработка тонального класификатора}
        % Архитектура проекта
        % Описать зависимости, а также что требуется реализовать.
        % Для решения задачи сентиментального анализа требуется:
        %   - классификатор (LibSVM)
        %   - модули обработки сообщений (Mystem + тональные префиксы + списки стоп слов)
        %
        % Выбор языка для реализации приложения
        %   - Python
        % хранения коллекций сообщений сети Twitter, а также вспомогательных данных:
        %   - База данных
        \subsubsection{Обработка сообщений сети Twitter}
        % Описать про модуль обработки.

        \subsubsection{Использование LibSVM для классификации методом <<Опорных векторов>>}
        % Описать про использование SVM классификатора

        \subsubsection{Вспомогательные признаки классификации}
        % Модуль добавления признаков в векторизацию сообщений.

    \subsection{Разработка вспомогательных инструментов}
    % Выбор языка для реализации вспомогательных инструментов приложения
    %   - Python
        \subsubsection{Прием текстовых сообщений сети Twitter}

        \subsubsection{Автоматическая тональная разметка принятых сообщений}

        \subsubsection{Создание лексиконов методом определения тональности словосочетаний}

    \subsection{Руководство пользователя}
        \subsubsection{Настройка компонентов приложения}
        % Здесь необходимо описать, какие предварительные действия требуется выполнить,
        % чтобы пользователь смог, пользоваться приложением.
        % Добавление лексиконов в хранилище
        Сборка и эксплуатация приложения проверялась под операционной системой
        {\tt Ubuntu 14.04 x64}. Изначально необходимо выполнить установку зависимостей.
        Список комманд представлен в листинге \ref{lst:dependencies}.
        \lstset{style=bash}
        \lstinputlisting[caption="Установка зависимостей проекта", label={lst:dependencies}]{parts/code/init.sh}

            % Инициализация обучающих коллекций
            По-умолчанию, приложение включает в себя обучающую/тестовую/эталонную
            коллекции соревнований {\tt SentiRuEval} за 2015 и 2016 года. Для
            инициализации коллекций в хранилище, пользователю необходимо выполнить
            последовательность комманд, представленных в листинге \ref{lst:collectionsInit}.
            \lstset{style=bash}
            \lstinputlisting[caption="Инициализация обучающих коллекций", label={lst:collectionsInit}]{parts/code/collectionsInit.sh}

            % Создание сбалансированных обучающих коллекций
            Применение балансировки к обучающей повышает качество оценки сообщений.
            \cite{diploma2015} В листинге \ref{lst:collectionsBalancedInit} приводится
            последовательность комманд, позволяющая создать сбалансированные коллекции
            на основе обучающих коллекций {\tt SentiRuEval}, дополненных сообщениями
            из "Корпуса коротких текстов" \cite{rubtsovaCollection}.
            \lstset{style=bash}
            \lstinputlisting[caption="Создание сбалансированных коллекций.", label={lst:collectionsBalancedInit}]{parts/code/collectionsBalancedInit.sh}

            % Инициализация лексиконов
            В приложении содержит по-умолчанию лексиконы, представленные в текстовом
            формате. Для применения лексиконов в классификаторе, необходимо преобразовать
            текстовые данные в хранилище. Для этого пользователю
            достаточно выполнить следующие действия, представленные в листинге
            \ref{lst:lexiconsInit}.
            \lstset{style=bash}
            \lstinputlisting[caption="Инициализация лексиконов по-умолчанию", label={lst:lexiconsInit}]{parts/code/lexiconsInit.sh}

        \subsubsection{Работа с приложением}

            % Векторизация сообщений обучающей и тестовых коллекций
            Для работы с приложением, пользователю необходимо перейти в каталог проекта {run},
            Каталог содержит настройки векторизации сообщений:
            % Добавить ссылку на описание формата
            \begin{itemize}
                \item {\tt msg.conf} --- описывает настройки семантической обработки текста
                    сообщений в формате {\tt JSON}.
                \item {\tt features.conf} --- предоставляет настройку списока
                    дополнительных признаков векторизации в формате {\tt JSON}.
            \end{itemize}

            Настройки параметров данных для классификации описаны в файле {\tt Makefile}.
            Каждая из настроек описывается именем, которое включает в себя
            характеристику следующих параметров (формат определения значений необходимых
            параметров представлен в листинге \ref{lst:makefile}):

            \begin{enumerate}
                \item {\tt TASK\_TYPE} -- тип решаемой задачи ({bank} или {ttk});
                \item {\tt TEST\_TABLE} -- имя тестовой коллекции в хранилище;
                \item {\tt TRAIN\_TABLE} -- имя обучающей коллекции в хранилище;
                \item {\tt MODEL\_NAME} -- имя используемой модели векторизации сообщений;
                \item {\tt ETALON\_RESULT} -- ссылка на эталонную коллекцию.
            \end{enumerate}

            \lstset{style=bash}
            \lstinputlisting[caption="Пример настройки параметров классификации в Makefile.",
                label={lst:makefile}]{parts/code/makefile.sh}

            Чтобы векторизовать содержимое обучающей и тестовых коллекций, а также
            произвести оценку качества работы классификатора,необходимо выполнить
            комманду:
            \begin{center}
                {\tt make {\{название\_настройки\}}}
            \end{center}

            По завершении процесса, вся необходимая информация по оценке качества
            работы будет отображена на экране в формате, представленном в листинге
            \ref{lst:classifierScores}.
            Для очистки каталога с результатами необходимо использовать следующую
            комманду:
            \begin{center}
                {\tt make clean\_results}
            \end{center}

%        \subsubsection{Создание лексиконов на основе сообщений сети
%            {\tt Twitter} }
%        Помимо существующих в приложении лексиконов, пользователю предоставляется
%        возможность создавать их c нуля. Пользователю необходимо выполнить следующую
%        последовательность действий (см. листинг \ref{lst:lexiconCreation}):
%        \begin{enumerate}
%            \item Подключиться к приему потока сообщений сети {\tt Twitter}. Пользователю
%                необходимо будет предварительно предоставить ключи авторизации;
%            \item На основе принятого потока, отфильтровать тональные сообщения
%            и создать два класса сообщений: положительные и негативные;
%            \item Сгенерировать лексикон на основе полученных классов.
%        \end{enumerate}
%
%        % Листинг выполнения подключения.
%        \lstset{style=bash}
%        \lstinputlisting[caption="Построение пользовательского лексикона.", label={lst:lexiconCreationPart1}]{parts/code/lexiconCreationPart1.sh}
%
%        % Листинг фильтрации собщений.
%
%        % Листинг генерации лексиконов.
