\newpage
\section{Обзор предметной области}
    % Объяснить, какие подходы к классификации рассматриваются в этой области.
    На сегодняшний день, большинство пользователей крупных социальных сетей,
    таких как Twitter, предпочитают высказывать свои отзывы и мнения о товарах
    и услугах в формате коротких сообщений. Возможность быстрого реагирования
    на сообщения со стороны компаний, предоставляемых эти услуги, возможно лишь
    в случае их автоматической обработки.

    Как известно, одним из направлений в решении задачи классификации является
    использование методов машинного обучения. Ввиду существенного роста объема
    доступной информации социальных сетей, такие проблемы как адаптация и
    обучение классификационных моделей становятся все менее значительными.
    В связи с этим, рассмотрим наиболее популярные методы машинного обучения \cite{svmAdvantages},
    которые находят свое применение к задачи тональной классификации сообщений.

    \subsection{Подходы к тональной классификации на основе методов машинного обучения}
        \label{sec:mlApproaches}
        Основой работы рассматриваемых методов является представление исходных
        сообщений $m$ в формате вектора нормализованых слов $\{f_1, f_2, \ldots, f_n\}$.
        В качеcтве значений каждой из размерности вектора $\vec{m}$ можно сопоставить
        $n_{f_i}(m)$ -- число вхождений терма $f_i$ в рассматриваемое сообщение $m$.
        Такая модель является вариацией {\it Bag Of Words} \cite{svmAdvantages}.
        В результате, сообщение $m$ представляет собой вектор:
        \begin{equation}
            \vec{m} = (n_1(m), n_2(m), \ldots, n_k(m)) \nonumber
        \end{equation}

        \subsubsection{Метод <<Наивного Байеса>>}
        % На основе статьи
        Один из подходов к класификации сообщений заключается в определении класса $c^{*}$,
        к которому относится рассматриваемое сообщение $m$ на основе метрики
        {\it максимального правдоподобия}:
        \begin{equation}
            c^{*} = argmax_c \hspace{2pt} P(c|m) \nonumber
        \end{equation}

        В основе вычисления условной вероятности $P(c|m)$ лежит правило Байеса:
        \begin{equation}
            \label{eq:BayesRule}
            P(c|m) = \dfrac{P(c, m)}{P(m)} = \dfrac{P(c)\cdot P(m|c)}{P(m)}
        \end{equation}

        Классификатор, построенный на основе правила, представленного в
        формуле \ref{eq:BayesRule}, называется {\it NB}-классификатором.
        Для оценки условной вероятности в формуле \ref{eq:BayesRule}, предполагается
        независимость термов сообщения, и вычисляется следующим образом:
        \begin{equation}
            P_{NB} (c|m) = \dfrac{P(c)\cdot(\Pi_{i=1}^{n}P(f_i|c)^{n_i(m)})}{P(m)} \nonumber
        \end{equation}

        Несмотря на простоту реализации алгоритма, независимость термов $f_i$ сообщения
        является ограничением для достижения реального правдоподобия. Работа \cite{nbAdvantages}
        демонстрирует оптимальность метода Наивного Байеса для большинства задач
        классификации, в которых присутствуют признаки, позволяющие установить
        тесную связь с соответствующими классами. В тоже время, использование
        более сложных методов позволяет добиться лучших результатов.

        %\subsubsection{Метод <<Максимальной энтропии>>}
        % Из статьи
        \subsubsection{Метод <<Опорных векторов>>}
        % 9.1.2
        В отличие от метода <<Наивного Байеса>>, подход на основе рассматриваемого
        метода предполагает поиск гиперплоскости, разделяющей сообщения разных классов.
        Построение выполняется на этапе обучения модели. На этом этапе решается задача
        поиска нормали $\vec{w}$ к гиперплоскости, причем разбиение классов должно
        производиться с максимально возможным отступом.

        Для поиска нормали составляется {\it оптимизационная задача с граничными
        условиями}:
        \begin{equation}
            \label{eq:optimizationSVM}
            \vec{w} = \sum_{j=1}^{N} \alpha_i c_i \vec{m_i}, \hspace{2pt} \alpha_i \geq 0
        \end{equation}

        В уравнении \ref{eq:optimizationSVM}, коэффициент $c_i \in \{-1, 1\}$
        указывает на принадлежность сообщения $m_i$ соответствующему классу;
        $\alpha_i$ -- коээфициент решения задачи двойной оптимизации. Среди всех
        векторов $\vec{m}$, для которых выполнено условие $\alpha_i > 0$, называются <<опорными>>.
        Определения класса, к которому относится рассматриваемый документ, осуществляется
        на основе стороны гиперплоскости, на которую падает проекция вектора $\vec{m}$.

        В общем случае, классификатор построенный на рассматриваемом подходе,
        позволяет достичь лучших резульатов классификации если сравнивать с
        аналогом на основе метода <<Наивного Байеса>> \cite{svmCompareVsNB}.

        (Дополнить на основе аналогичного раздела из \cite{islr})

        % SVM with multiple classes
    \subsection{Признаки, используемые для классификации сообщений}
        % Лемматизация термов сообщения на основе метрик
        \subsubsection{Векторизация сообщений}
        % bag of words
        Под термином {\it сообщение} будем понимать вектор, состоящий из
        нормализованных слов -- {\it термов}. Векторизация сообщения -- процесс
        преобразования сообщения в вектор, в котором каждому терму сообщения
        сопоставляется некоторое числовое значение.

        В п. \ref{sec:mlApproaches} рассматривался один из самых простых
        способов векторизации сообщений: {\it Bag Of Words}. Помимо факта присутствия
        терма и числа его вхождения в сообщение, такая векторизация не несет в
        себе никакой дополнительной информации терма относительно всей коллекции
        сообщений.

        % tf-idf
        В качестве дополнительной информации, в векторизацию сообщения может
        быть заложена частота встречаемости термов. Для определния такой частоты
        используется мера {\it tf-idf}, которая вычисляется следующим образом:

        \newcommand\tfidf{\mathop{\mbox{$tf$-$idf$}}}
        \begin{equation}
            \label{eq:tfidf}
            \tfidf(t,d,D) = tf(t,d) \cdot idf(t, D)
        \end{equation}

        В формуле \ref{eq:tfidf}, параметр $t$ -- терм, $d$ -- документ, являющийся
        элементом коллекции документов $D$. Функция {\it tf} определяет {\it частоту встречаемости}
        (от англ. {\it term frequency}) терма $t$ в документе $d$ (см. формулу \ref{eq:tf}).
        \begin{equation}
            \label{eq:tf}
            tf(t, d) = \dfrac{n_i}{|d|}
        \end{equation}

        Под {\it idf } мерой понимается {\it инвертированная частота терма} (от англ.
        {\it inverted document frequency}) в коллекции документов, и определяется
        формулой \ref{eq:idf}. Чем больше значение {\it idf(t, d)}, тем выше уровень
        ``уникальности'' рассматриваемого терма $t$ для коллекции документов $D$.
        \begin{equation}
            \label{eq:idf}
            idf(t, d) = log \Bigg[ \dfrac{|D|}{|\{d_i \in D | t_i \in d_i|\}|} \Bigg]
        \end{equation}

        % tf-idf + вспомогательный словарь.
        \subsubsection{Вспомагательные признаки для сообщений}
        %
        Для повышения качества классификации, вектор каждого сообщения можно дополнить
        вспомогательными признаками. Основная задача, которая ставится при введении
        признаков -- это отделение одного множества классов от другого, при том что
        оба множества не являются пустыми. Примерами таких признаков могут служить:
        \begin{itemize}
            \item Учет {\it эмотиконов} в сообщении: <<:)>>, <<;D>>, <<:(>>, <<((>>, и т.д.;
            \item Учет знаков препинания: <<?>>, <<!>>, <<...>>, и т.д.;
            \item Учет числа слов написанных в верхнем регистре.
            \item Признаки на основе предварительно составленых {\it тональных лексиконов}.
        \end{itemize}

        Признаки, построенные на основе первых трех пунктов, позвяют примерно разделить
        множество неэмоциональных сообщений от эмоциональных.

        Использование вспомогательных признаков на основе тональных лексиконов
        позволяет предварительно произвести оценку сообщения, и тем самым
        <<подсказать>> классификатору наиболее вероятный класс сообщения.

    \subsection{Способы построения тональных лексиконов}

    В любом предложении естественного языка, содержатся ключевые слова ( и словосочетания),
    на основании которых можно извлечь дополнительную информацию. Если рассматривать
    предложение с точки зрения тонального анализа, то некоторые слова могут
    придавать негативную или положительную окраску всему сообщению в целом.
    В связи с этим, умение точно извлекать тональные слова или словосочетания
    с целью составления дополнительной метаинформации о предложении (сообщении),
    может оказать положительное влияние на качество классификации.

    Можно сказать, что возникает необходимость в словаре, состоящего из пар
    $<w, t>$, где $w$ -- слово или словосочетание, а $t$ -- его оценка.
    Словарь, представленный в таком формате называется {\it лексиконом}.
    Задача, которую решает лексикон в области тонального анализа -- сопоставление
    тональной окраски для каждого слова содержащегося в нем.
    Очевидно, что формализация оценочного параметра приводит к представлению
    параметра $t$ в формате числового значения, возможно с учетом знака.
    Обычно в качестве оценки рассматривают действительные значения в области
    $\left[ -1, 1\right]$.

    Рассмотрим основные методы вычисления оценочных параметров, на основе которых
    возможно автоматическое создания тональных лексиконов.

        \subsubsection{Вычисление оценки на основе метрики log-likelihood}
        Метод, предложенный в \cite{lexiconLL} предполагает наличие двух корпусов, на основании
        которых вычисляется частотная оценка принадлежности слова к каждому из корпусов.
        В общем случае, под <<словом>> понимается терм предложения, однако
        реальное приминение в \cite{lexiconLL} находит свое место в составлении
        списка частот для определенных частей речи.

        Тем не меннее, в общем случае для подсчета на уровне термов {\it ожидаемой
        степени принадлежности} $E_i(w)$, применяется следующая формула:
        \begin{equation}
            \label{eq:classDifference}
            E_i(w) = \dfrac{N_i\sum\limits_{j=1}^{2}O_i(w)}{\sum\limits_{j=1}^{2}N_i}
        \end{equation}

        Здесь, параметр $i$ является индексом коллекции, $O_j(w)$ -- обозреваемое
        значение, которое соответствует числу вхождений $w$ в корпус $j$, а $N_j$
        -- общее число слов в корпусе $j$.

        Далее, на основании полученных степеней принадлежности терма соответствующему
        классу, применяют метрику log-likelihood для вычисления степени <<важности>>
        терма:
        \begin{equation}
            \label{eq:loglikelihood}
            - \ln \lambda = \sum\limits_i O_i \ln \left( \dfrac{O_i}{E_i} \right)
        \end{equation}

        Если произвести сортировку словаря на основе формулы параметра формулы
        \ref{eq:loglikelihood} в формате убывания значения, то вершину списка
        будут представлять термы $w$, для которых наблюдается большая разница в
        степени принадлежности рассматриваемых корпусов. Соответственно, термы
        с минимальной разницой окажутся в конце отсортированного списка.

        Степень важности терма является положительной величиной. Дополнительно можно
        ввести знаковый параметр на основании разницы между показаниями формулы
        \ref{eq:classDifference} для двух классов.

        \subsubsection{Предсказывание семантической ориентации прилагательных}
        \label{sec:adjectivesPrediction}
        В работе \cite{lexiconAdjectives} рассматривается способ определения
        тональной оценки прилагательных, которые являются аргументами конъюнктов.
        Основой подхода является гипотеза об ограничении ориентации прилагательных
        в зависимости от типа объединяющего из конъюнкта и наличия префиксов отрицаний:
        %В таких лингвистических конструкциях как конъюнкты, связь и ориентация
        %аргументов зависит от способа их соединения:
        \begin{center}
            \it
            Этот бриллиант \underline{красивый} {\bfи} \underline{дорогой}

            Бриллиант \underline{красивый}, {\bfно} \underline{дорогой}

            Это украшение \underline{некрасивое} {\bfи} \underline{дорогое}

            Украшение \underline{некрасивое}, {\bfно} \underline{дорогое}
        \end{center}

        Для построения автоматического извлечения семантически ориентированой
        информации на основе содержимого корпуса большого объема.
        Извлечение и оценка тональности прилагательных, а также связей между ними
        реализуется следующими этапами:
        \begin{enumerate}
            \item Из корпуса выбираются все конъюнкты с релевантными
                морфологическими связями.

                Извлечение конъюнктов выполнялось с помощью формальной
                грамматики, примененной к корпусу из 21 миллиона словоформ.
                В результате было собрано около 15 тысяч пар прилагательных;

            \item Применяется регерессионная модель для объединения информации
                разных конъюнктов с целью определения ориентации каждой из связанных пар.
                Результатом является граф с одинакого либо разноориентированными
                связями между прилагательными;
            \item Разделение прилагательных на две группы с разными ориентациями
                с помощью алгоритма кластеризации. Каждая группа включает в себя
                максимально возможное число прилагательных.
                % 6 (если нужно более подробно)
                Для этого, к построенному графу применяется функция $\Phi$,
                параметром которой является $\mathcal{P}$ -- разбиение множества
                прилагательных на группы $C_1$ и $C_2$:
                \begin{equation}
                    \Phi(\mathcal{P}) = \sum\limits_{i=1}^2 \Bigg( \dfrac{1}{|C_i|} \sum\limits_{x,y \in C_i, \\ x \neq y} d(x,y) \Bigg)
                \end{equation}
                Где $|C_i|$ -- мощность соответствующего класса; $d(x, y)$ --
                степень различия прилагательных $x$ и $y$.
                Далее, осуществляется поиск параметра $\mathcal{P}_{min}$ для
                построения наилучшего разбиения;

            \item Для групп $C_i, \hspace{4pt} i=\overline{1,2}$ вычисляются
                средние частоты упоминания входящих в них прилагательных.
                Та группа, для которой полученное значение наибольшее --
                маркируется как тонально-положительная.
                % 7
                Ранее, в работе \cite{lexiconAdjectivesPrevious} показывается,
                что противопоставление качественным прилагательным (т.е.
                прилагательные противоположной группы) в 81\% случаев оказывается
                семантически неразмеченным. Отмечается, что этот факт демонстрирует
                корелляцию с ориентацией прилагательного, которая наиболее вероятно
                является положительной.
        \end{enumerate}

        Применение описанного выше подхода к задаче классификации конъюнктов
        позволили добиться довольно высоких показаний точности (91\% и выше).
        Отмечается потенциальная возможность применения метода к другим
        частям речи.

        \subsubsection{Вычисление оценки на основе тональности словосочетаний}
        В работе \cite{lexiconSO} предлагается подход который в отличие от
        статьи \cite{lexiconAdjectives}, рассмотренной в п. \ref{sec:adjectivesPrediction},
        применим к любым словосочатаниям. Алогоритм состоит из выполнения следующих шагов:
        \begin{enumerate}
            \item Извлечение {\it синтаксических конструкций}, для которых будет производиться
                дальнейшая оценка. В качестве таких конструкций могут быть фразы, содержащие
                прилагательные или наречия. [Ссылка на предыдущую работу]. В тоже время,
                при извлечении одной лишь части речи может возникнуть проблема нехватки контекста
                для определения оценки. Так, например прилагательное <<непредсказуемость>>
                может иметь как негативную окраску в словосочетании <<непредсказуемое поведение>>,
                так и положительную: <<непредсказуемый сюжет>>.
            %Далее, под термином <<слово>> будем понимать произвольную синтаксическую конструкцию, извлеченную
            %из текста.
            \item Производится оценка извлеченных синтаксических конструкций на основе
                меры взаимной информации ({\it Pointwise Mutation Information, PMI}).
                Вычисление меры производится между двумя словами $word_1$ и $word_2$,
                и определяется следующим образом:
                \begin{equation}
                    \label{eq:pmi}
                    PMI(word_1, word_2) = log_2 \Bigg[ \dfrac{P(word_1 \hspace{4pt} \&\& \hspace{4pt} word_2)}{P(word_1) \cdot P(word_2)} \Bigg]
                \end{equation}

                Где $P(word_1 \hspace{4pt} \&\& \hspace{4pt} word_2)$ -- вероятность
                размещения слов $word_1$ и $word_2$ вместе. Соотношение числителя
                к знаменателю в формуле \ref{eq:pmi} определяет степень зависимость одного
                слова от другого.

                Семантической ориентацией ({\it Semantic Orientation, SO}), для рассматриваемой
                конструкцией называется величина, которая вычисляется на основе
                тональных меркеров $ ``positive\text{''}$ и $``poor\text{''}$, являющихся аргументами
                меры точечной взаимоинформации:
                \begin{equation}
                    \label{eq:so}
                    SO(word) = PMI(word, ``excellent\text{''}) - PMI(word, ``poor\text{''})
                \end{equation}

                Наибольшее значение в формуле \ref{eq:so} достигается в случае
                наличия наибольшей связи рассматриваемой конструкции $phrase$
                с маркером $ ``excellent\text{''}$; наименьшее, в случае наибольшей связи
                с $ ``poor\text{''}$ маркером.

                Формула \ref{eq:pmi} рассматривалась применительно к параметрам
                {\it word}. Для вычисления уравнения \ref{eq:so} от параметра
                $phrase$, используется функция на основе числа совпадений
                $hits(phrase)$, а также оператор {\it NEAR} расположения слов в
                непосредственной близости. В сочетании с формулами \ref{eq:pmi}
                и \ref{eq:so}, семантическая ориентация вычисляется следующим
                образом:
                \begin{equation}
                    \label{eq:soPhrase}
                    SO(phrase) = log_2 \Bigg[ \dfrac{hits(phrase \hspace{4pt} NEAR \hspace{4pt}``excellent\text{''})hits(``poor\text{''}) }{hits(phrase \hspace{4pt}NEAR \hspace{4pt}``poor\text{''})hits(``excellent\text{''})} \Bigg]
                \end{equation}

            \item Для подсчета оценки могут быть использованы формулы \ref{eq:so} и
                \ref{eq:soPhrase}.
        \end{enumerate}

        Эксперименты, проведенные для набора из 410 обзоров с ресурса мнений пользователей {\it Epinions},
    показывают среднюю точность классификации порядка 74\%. Как оказалось, самым
    сложным источником для анализа оказались обзоры на фильмы; на такой коллекции
    точность классификации опустилась до уровня 64\%. Наилучшие показатели были
    достигнуты на коллекциях мнений об автомобилях и банках, на которых точность
    оказалась в пределах 80--84\%.

    \subsection{Оценка качества классификационной модели}
    % Посмотреть обзоры из обзора соревнований.

        \subsubsection{Точность и полнота}
    Чтобы произвести оценку качества работы классификатора на некотором наборе
    сообщений, необходимо чтобы для этого набора существовали эталонные
    значения. Применительно к задаче тональной классификации, под значениями
    понимается класс, к которому необходимо отнести соответствующее сообщение.

    Таким образом, для каждого сообщения ответ может быть получен как со стороны
    классификатора, так и группой экспертов. Все возможные случаи ответов
    для фиксированного класса $A$ удобнее всего представить в таблице
    \ref{table:contingent}. Такое представление носит название
    {\it таблицы контингентности}.

    \begin{table}[H]
        \centering
        \caption{Таблица контингентности для класса $A$}
        \label{table:contingent}
        \begin{tabular}{|c|c|c|c|}
            \hline
            \multicolumn{2}{|c|}{\multirow{2}{*}{Принадлежность cообщений к классу $A$}} &     \multicolumn{2}{c|}{эксперты}                     \\ \cline{3-4}
            \multicolumn{2}{|c|}{}                                              &   положительная             & отрицательная                           \\ \hline
            \multirow{2}{*}{классификатор}          & положительная             & {\cellcolor[HTML]{9AFF99} $TP$} & {\cellcolor[HTML]{FFCCC9} $FP$}     \\ \cline{2-4}
                                                    & отрицательная             & {\cellcolor[HTML]{FFCCC9} $FN$} & {\cellcolor[HTML]{9AFF99} $TN$}     \\ \hline
        \end{tabular}
     \end{table}

     на основе таблицы \ref{table:contingent} можно рассчитать следующие
     характеристики качества работы классификатора для соответсвующего класса:
    \begin{itemize}
        \item {\bf полнота} -- число найденных сообщений, которые
            действительно принадлежат соответствующему классу относительно всех
            сообщений соответсвующего класса:

            \begin{equation}
                \label{eq:recall}
                r_a = \dfrac{tp}{tp + fn} \hspace{20pt}
            \end{equation}

        \item {\bf точность} -- количество сообщений, которое
            классификатор правильно отнес к соответсвующему классу по отошению
            ко всему объему сообщений определенных системой в этот класс:

            \begin{equation}
                \label{eq:precision}
                p_a = \dfrac{tp}{tp + fp} \hspace{20pt}
            \end{equation}
    \end{itemize}

        на практике возникает необходимость в метрике, которая бы позволяла одновременно
    обе характеристики: точность и полноту. для этого предусмотрена $f-мера$, которая
    в общем случае вычисляется по формуле:
    \begin{equation}
        \label{eq:fmeasurecommon}
        f(\beta) = \dfrac{(1+\beta^2) p \cdot r}{\beta^2 \cdot p + r}
    \end{equation}

    в случае, если $\beta = 1$, то формула \ref{eq:fmeasurecommon} преобразуется
    к гармоническому среднему:
    \begin{equation}
        \label{eq:fmeasure}
        f_1 = \dfrac{2 \cdot p r}{p + r}
    \end{equation}

    \subsubsection{$f_1-micro$ и $f_1-macro$ меры качества}
    рассмотрим случай, когда необходимо рассмотреть параметры качества работы
    классификатора относительно нескольких классов одновременно.
    пусть имеется два класса, относительно которых будут вычисляться параметры полноты, точности,
    и f-меры.
    oтностельно каждого класса можно составить таблицы контингентности,
    аналогичные таблице \ref{table:contingent}.

    одним из методов вычисления среднего значения параметров точности и полноты,
    является {\it микроусреднение} \cite{micromacromeasures}:
    \begin{itemize}
        \item {\it микроусреднением полноты} --- называется величина, которая
            вычисляется аналогично формуле \ref{eq:recall}, только на основании
            двух классов:
            \begin{equation}
                r_{micro_{(1, 2)}} = \dfrac{tp_{1} + tp_{2}}{tp_{1} + tp_{2} + fp_{1} + fp_{2}} \nonumber
            \end{equation}
        \item {\it микроусреднением точности} --- называется величина,
            которая вычисляется аналогично формуле \ref{eq:precision},
            на основании двух классов:
            \begin{equation}
                p_{micro_{(1, 2)}} = \dfrac{tp_{1} + tp_{2}}{tp_{1} + tp_{2} + fn_{1} + fn_{2}} \nonumber
            \end{equation}
    \end{itemize}

%    далее, подставляя параметры $p_{micro}$, $p_{macro}$ в формулу \ref{eq:fmeasure},
%    получим {\it микроусредненную меру $f_1$}:

    другой метод усреднения значений полноты и точности называется {\it макроусреднением} \cite{micromacromeasures}.
    параметры на основе такого подхода, вычисляются следующим образом:
    \begin{itemize}
        \item {\it макроусреднение полноты} --- вычисление средних значений параметров
            полноты на основе каждого из классов:
            \begin{equation}
                r_{macro_{(1, 2)}} = \dfrac{r_{1} + r_{2}}{2} \nonumber
            \end{equation}
        \item {\it макроусреднение точности} --- вычисление средних значений параметров
            точности, вычисленных отдельно на основе каждого из классов:
            \begin{equation}
                p_{macro_{(1, 2)}} = \dfrac{p_{1} + p_{2}}{2} \nonumber
            \end{equation}
    \end{itemize}

    таким образом, на основе каждого из метода усреднений может быть вычислена
    $f_1$ мера:
    \begin{equation}
        \label{eq:fmacro12}
        f_{1_{macro_{(1,2)}}} = \dfrac{2 \cdot p_{macro_{(1,2)}} r_{macro_{(1,2)}} }{p_{macro_{(1,2)}} + r_{macro_{(1,2)}}}
    \end{equation}
    \begin{equation}
        \label{eq:fmicro12}
        f_{1_{micro_{(1,2)}}} = \dfrac{2 \cdot p_{micro_{(1,2)}} r_{micro_{(1,2)}} }{p_{micro_{(1,2)}} + r_{micro_{(1,2)}}}
    \end{equation}

    % про ф-меру сюда же

    мaкроусреднение придает одинаковый вес каждому из усредняемых классов, в то
    время как при микроусреднении вес учитывается на основе числа документов в
    классе. поскольку $f_{macro}$ мера игнорирует параметр $tn$, то смещение
    среднего значения будет производиться в сторону того класса, для которого классификатор сработал
    лучше (большее значение $tp$); в тоже время, при использовании $f_{micro}$,
    смещение будет произведено в сторону наибольшего класса. \cite{micromacromeasures}

    таким образом, результаты полученные на основе микроусреднения являются мерой
    эффективности на коллекциях большого объема. для получения аналогичного эффекта
    на коллекциях малого объема, необходимо использовать макроусреднение. \cite{micromacromeasuresdifferences}

    \subsection{соревнования в области тональной классификации сообщений}
    % цель задачи
    за последние несколько лет, в области автоматической обработки текстовых сообщений
    активно набирает популярность платформа открытого тестирования систем
    тонального анализа русскоязычных сообщений {\it sentirueval} \cite{tonalityanalisys}.
    тестирование проводится в формате соревнований, к которым организаторы заранее подготавливают
    коллекции данных. данные представляют собой сообщения сети {\it twitter}, каждое из которых
    выражает положительное либо негативное мнение автора по отношению к рассматриваемой
    в собщении организации. среди предментных областей доступны следующие коллекции
    данных:
    \begin{itemize}
        \item сообщения о банковских компаниях;
        \item сообщения о телекоммуникационных компаниях.
    \end{itemize}

    тональная классификация заключается в определении оценки по отношению к
    рассматриваемой в сообщении компании. сообщения, для которых пользователям
    необходимо проставить оценку, представляются в {\it тестовой коллекции}. изначально все
    сообщения тестовой коллекции отмечены как <<нейтральные>>, и имеют оценку <<0>>.
    участнику предлагается изменить значение оценки на <<1>> если отношение к
    рассматриваемой организации <<положительное>>, или на <<-1>> в случае
    <<негативного>> отношения.

    % про коллекции (почему они несбалансированы, процентное соотношение твитов)

    помимо тестовых коллекций, организаторы также подготавливают {\it обучающие} и
    {\it эталонные} коллекции для каждой из областей. последние, в свою очередь,
    доступны после окончания соревнований. данные для коллекций собираются на
    основе {\it streaming api twitter}. отмечается, что при сборе данных отсутствует
    искусственное завышение классов с малым числом сообщений \cite{tonalityanalisys}.
    так, во всех предметных областях преобладают сообщения с нейтральной оценкой (см. таблицы
    \ref{table:traintablestat} и \ref{table:testtablestat}).

    \begin{table}[h]
        \centering
        \caption{распределение объемов классов сообщений в обучающих коллекциях}
        \label{table:traintablestat}
        \begin{tabular}{|c|c|c|}
            \hline
            oбласть     & нейтральные \%    & тональные  \%     \\ \hline
             tkk        & 47,59             & 52,42             \\ \hline
             banks      & 58,35             & 41,65             \\ \hline
        \end{tabular}
     \end{table}

    \begin{table}[h]
        \centering
        \caption{распределение объемов классов сообщений в тестовых коллекциях}
        \label{table:testtablestat}
        \begin{tabular}{|c|c|c|}
            \hline
            oбласть     & нейтральные \%    & тональные  \%     \\ \hline
             tkk        & 67,70             & 32,30             \\ \hline
             banks      & 77,90             & 22,10             \\ \hline
        \end{tabular}
     \end{table}
    % система оценки (метрики, используемые для оценки классификационной модели)
    для {\it оценки качества} классификатора, используются макро- и микроусреднения
    $f_1$-меры для классов положительных и негативных сообщений. вычисление
    $f_{macro(pos, neg)}$ и $f_{micro(pos, neg)}$ производится на основе
    формул \ref{eq:fmacro12} и \ref{eq:fmicro12} соответственно. нейтральный
    класс сообщения в оценке не участвует. однако в случае, если классификатор
    некорректно определяет тональное сообщение, то это выявляется в расхождении
    мнения классификатора и эксперта в таблицах контингентностей, составленных для
    классов $pos$ и $neg$, на основании которых высчитываются параметры полноты
    и точности.

    % Результаты
    Результаты участников сравниваются относительно нижнего порогового значения -- {\it baseline}.
    В качестве такого порога рассматривается классификатор, который для каждого
    сообщения проставляет тональную оценку наиболее частотного класса. В таблицах
    \ref{table:exampleResultsBanks} и \ref{table:exampleResultsTTK} рассматривается
    прогоны, демонстрирующие лучшие результаты в сравненнии с нижним пороговым
    значением. Параметры прогонов следующие \cite{tonalityAnalisys}:
    \begin{enumerate}
        \item Классификатор {\it SVM}, с учетом признаков:
            нормализованные леммы, установление связи между леммами;
        \item Метод максимальной энтропии с учетом признаков:
            n-граммы (слов и символьные), дополнительные результаты моделирования;
        \item Классификатор {\it SVM} c учетом: n-граммы (словесные и буквенные),
            знаки пунктуации, наличие ссылок, символы <<ретвита>>, использование
            эмоционально окрашенного словаря.
    \end{enumerate}

    \begin{table}[H]
        \centering
        \caption{Результаты качества работы лучшего прогона в сравнении с {\it baseline}.
        {\it SentiRuEval-2015}, колекция сообщений о банках}
        \label{table:exampleResultsBanks}
        \begin{tabular}{|c|c|c|}
        \hline
        №                       &       $F_{macro(pos, neg)}$        & $F_{micro(pos, neg)}$  \\ \hline
        baseline                &           0.1267                      &       0.2377              \\ \hline \hline
        1                       &           0.3354                      &       0.3656              \\ \hline
        2                       &           0.3598                      &       0.3430              \\ \hline
        3                       &           0.3520                      &       0.3370              \\ \hline
        \end{tabular}
     \end{table}

     \begin{table}[H]
        \centering
        \caption{результаты качества работы лучшего прогона в сравнении с {\it baseline}.
        {\it sentirueval-2015}, колекция телекоммуникационных сообщений}
        \label{table:exampleResultsTTK}
        \begin{tabular}{|c|c|c|}
        \hline
        №                       &       $F_{macro(pos, neg)}$        & $F_{micro(pos, neg)}$  \\ \hline
        baseline                &           0.1823                      &       0.3370              \\ \hline \hline
        1                       &           0.4882                      &       0.5355              \\ \hline
        2                       &           0.4670                      &       0.5060              \\ \hline
        3                       &           0.4477                      &       0.5282              \\ \hline
        \end{tabular}
     \end{table}

    % Анализ (почему наблюдается разница в результатах между задачами)
    Как можно заметить, показания таблиц \ref{table:exampleResultsBanks} и \ref{table:exampleResultsTTK}
    демонструют значительную разницу в максимумах для каждого из прогонов двух областей. Для выявляения причины, вызвавшей
    такое расхождение, в \cite{tonalityAnalisys} проводится подсчет разницы между обучающей
    и тестовых коллекцией для каждой из областей на основе:
    \begin{itemize}
        \item Несимметричная мера удаленности -- дивергенция Кульбака-Лейблера;
        \item Симметричная мера Йенсена-Шеннона.
    \end{itemize}

    Результaты показали, что наибольшее расхождение между коллекциями наблюдалось в
    области банков.

    Такое расхождение может быть объяснено тем, что коллекции для каждой из областей
    были подготовлены в разные периоды времени. Обучающие коллекции составлены в
    период июнь-август 2014 года, в момент разгара боевых действий на Украине.
    В тоже время, данные для тестовых коллекций были получены {\it на пол года раньше}, в период с
    декабря 2013 по февраль 2014.

    % Ориентация на анализ
    Несмотря на то, что в сообщениях могло упоминаться отношение к нескольким
    компаниям одновременно, большинство участников все равно предпочли
    оценивать сообщение в целом. Участники с такой стратегией показали
    более высокие результаты чем те, кто пытался производить оценку для каждой
    компании в отдельности. Отсюда можно сделать вывод, что на сегодняшний момент
    задача по тональной оценке отдельных объектов сообщения является весьма
    ограниченной \cite{tonalityAnalisys}.
