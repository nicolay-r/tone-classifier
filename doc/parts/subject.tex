\newpage
\section{Обзор предметной области}
    % Объяснить, какие подходы к классификации рассматриваются в этой области.
    На сегодняшний день, большинство пользователей крупных социальных сетей,
    таких как \twitter, предпочитают высказывать свои отзывы и мнения о товарах
    и услугах в формате коротких сообщений. Возможность быстрого реагирования
    на сообщения со стороны компаний, предоставляемых эти услуги, возможно лишь
    в случае их автоматической обработки.

    Как известно, одним из направлений в решении задачи классификации является
    использование методов машинного обучения. Ввиду существенного роста объема
    доступной информации социальных сетей, такие проблемы как адаптация и
    обучение классификационных моделей становятся все менее значительными.
    В связи с этим, рассмотрим наиболее популярные методы машинного обучения \cite{svmAdvantages},
    которые находят свое применение к задачи тональной классификации сообщений.

    \subsection{Подходы к тональной классификации на основе методов машинного обучения}
        \label{sec:mlApproaches}
        Основой работы рассматриваемых методов является представление исходных
        сообщений $m$ в формате вектора нормализованых слов $\{F_1, F_2, \ldots, F_n\}$.
        В качеcтве значений каждой из размерности вектора $\vec{m}$ можно сопоставить
        $n_{F_i}(m)$ -- число вхождений терма $F_i$ в рассматриваемое сообщение $m$.
        Такая модель является вариацией {\it Bag Of Words} \cite{svmAdvantages}.
        В результате, сообщение $m$ представляет собой вектор:
        \begin{equation}
            \vec{m} = (n_1(m), n_2(m), \ldots, n_k(m))
        \end{equation}

        \subsubsection{Метод <<Наивного Байеса>>}
        % На основе статьи
        Один из подходов к класификации сообщений заключается в определении класса $c^{*}$,
        к которому относится рассматриваемое сообщение $m$ на основе метрики
        {\it максимального правдоподобия}:
        \begin{equation}
            c^{*} = argmax_c \hspace{2pt} P(c|m)
        \end{equation}

        В основе вычисления условной вероятности $P(c|m)$ лежит правило Байеса:
        \begin{equation}
            \label{eq:BayesRule}
            P(c|m) = \dfrac{P(c, m)}{P(m)} = \dfrac{P(c)\cdot P(m|c)}{P(m)}
        \end{equation}

        Классификатор, построенный на основе правила, представленного в
        формуле \ref{eq:BayesRule}, называется {\it NB}-классификатором.
        Для оценки условной вероятности в формуле \ref{eq:BayesRule}, предполагается
        независимость термов сообщения, и вычисляется следующим образом:
        \begin{equation}
            P_{NB} (c|m) = \dfrac{P(c)\cdot(\Pi_{i=1}^{n}P(F_i|c)^{n_i(m)})}{P(m)} \nonumber
        \end{equation}

        Несмотря на простоту реализации алгоритма, независимость термов $F_i$ сообщения
        является ограничением для достижения реального правдоподобия. Работа \cite{nbAdvantages}
        демонстрирует оптимальность метода Наивного Байеса для большинства задач
        классификации, в которых присутствуют признаки, позволяющие установить
        тесную связь с соответствующими классами. В тоже время, использование
        более сложных методов позволяет добиться лучших результатов.

        %\subsubsection{Метод <<Максимальной энтропии>>}
        % Из статьи
        \subsubsection{Метод <<Опорных векторов>>}
        % 9.1.2
        В отличие от метода <<Наивного Байеса>>, подход на основе рассматриваемого
        метода предполагает поиск гиперплоскости, разделяющей сообщения разных классов.
        Построение выполняется на этапе обучения модели. На этом этапе решается задача
        поиска нормали $\vec{w}$ к гиперплоскости, причем разбиение классов должно
        производиться с максимально возможным отступом.

        Для поиска нормали составляется {\it оптимизационная задача с граничными
        условиями}:
        \begin{equation}
            \label{eq:optimizationSVM}
            \vec{w} = \sum_{j=1}^{N} \alpha_i c_i \vec{m_i}, \hspace{2pt} \alpha_i \geq 0
        \end{equation}

        В уравнении \ref{eq:optimizationSVM}, коэффициент $c_i \in \{-1, 1\}$
        указывает на принадлежность сообщения $m_i$ соответствующему классу;
        $\alpha_i$ -- коээфициент решения задачи двойной оптимизации. Среди всех
        векторов $\vec{m}$, для которых выполнено условие $\alpha_i > 0$, называются <<опорными>>.
        Определения класса, к которому относится рассматриваемый документ, осуществляется
        на основе стороны гиперплоскости, на которую падает проекция вектора $\vec{m}$.

        В общем случае, классификатор построенный на рассматриваемом подходе,
        позволяет достичь лучших резульатов классификации если сравнивать с
        аналогом на основе метода <<Наивного Байеса>> \cite{svmCompareVsNB}.

        (Дополнить на основе аналогичного раздела из \cite{islr})

        % SVM with multiple classes
    \subsection{Признаки, используемые для классификации сообщений}
        % Лемматизация термов сообщения на основе метрик
        \subsubsection{Векторизация сообщений}
        % bag of words
        Под термином {\it сообщение} будем понимать вектор, состоящий из
        нормализованных слов -- {\it термов}. Векторизация сообщения -- процесс
        преобразования сообщения в вектор, в котором каждому терму сообщения
        сопоставляется некоторое числовое значение.

        В п. \ref{sec:mlApproaches} рассматривался один из самых простых
        способов векторизации сообщений: {\it Bag Of Words}. Помимо факта присутствия
        терма и числа его вхождения в сообщение, такая векторизация не несет в
        себе никакой дополнительной информации терма относительно всей коллекции
        сообщений.

        % tf-idf
        В качестве дополнительной информации, в векторизацию сообщения может
        быть заложена частота встречаемости термов. Для определния такой частоты
        используется мера {\it tf-idf}, которая вычисляется следующим образом:

        \newcommand\tfidf{\mathop{\mbox{$tf$-$idf$}}}
        \begin{equation}
            \label{eq:tfidf}
            \tfidf(t,d,D) = tf(t,d) \cdot idf(t, D)
        \end{equation}

        В формуле \ref{eq:tfidf}, параметр $t$ -- терм, $d$ -- документ, являющийся
        элементом коллекции документов $D$. Функция {\it tf} определяет {\it частоту встречаемости}
        (от англ. {\it term frequency}) терма $t$ в документе $d$ (см. формулу \ref{eq:tf}).
        \begin{equation}
            \label{eq:tf}
            tf(t, d) = \dfrac{n_i}{|d|}
        \end{equation}

        Под {\it idf } мерой понимается {\it инвертированная частота терма} (от англ.
        {\it inverted document frequency}) в коллекции документов, и определяется
        формулой \ref{eq:idf}. Чем больше значение {\it idf(t, d)}, тем выше уровень
        ``уникальности'' рассматриваемого терма $t$ для коллекции документов $D$.
        \begin{equation}
            \label{eq:idf}
            idf(t, D) = log \Bigg[ \dfrac{|D|}{|\{d_i \in D | t_i \in d_i|\}|} \Bigg]
        \end{equation}

        % tf-idf + вспомогательный словарь.
        \subsubsection{Вспомагательные признаки для сообщений}
        \label{sec:additionalFeatures}

        Для повышения качества классификации, вектор каждого сообщения можно дополнить
        вспомогательными признаками. Основная задача, которая ставится при введении
        признаков -- это отделение одного множества классов от другого, при том что
        оба множества не являются пустыми. Примерами таких признаков могут служить:
        \begin{itemize}
            \item Учет {\it эмотиконов} в сообщении: <<:)>>, <<;D>>, <<:(>>, <<((>>, и т.д.;
            \item Учет знаков препинания: <<?>>, <<!>>, <<...>>, и т.д.;
            \item Учет числа слов написанных в верхнем регистре.
            \item Признаки на основе предварительно составленых {\it тональных лексиконов}.
        \end{itemize}

        Признаки, построенные на основе первых трех пунктов, позвяют примерно разделить
        множество неэмоциональных сообщений от эмоциональных.

        Использование вспомогательных признаков на основе тональных лексиконов
        позволяет предварительно произвести оценку сообщения, и тем самым
        <<подсказать>> классификатору наиболее вероятный класс сообщения.

    \subsection{Способы построения тональных лексиконов}

    В любом предложении естественного языка, содержатся ключевые слова ( и словосочетания),
    на основании которых можно извлечь дополнительную информацию. Если рассматривать
    предложение с точки зрения тонального анализа, то некоторые слова могут
    придавать негативную или положительную окраску всему сообщению в целом.
    В связи с этим, умение точно извлекать тональные слова или словосочетания
    с целью составления дополнительной метаинформации о предложении (сообщении),
    может оказать положительное влияние на качество классификации.

    Можно сказать, что возникает необходимость в словаре, состоящего из пар
    $<w, t>$, где $w$ -- слово или словосочетание, а $t$ -- его оценка.
    Словарь, представленный в таком формате называется {\it лексиконом}.
    Задача, которую решает лексикон в области тонального анализа -- сопоставление
    тональной окраски для каждого слова содержащегося в нем.
    Очевидно, что формализация оценочного параметра приводит к представлению
    параметра $t$ в формате числового значения, возможно с учетом знака.
    Обычно в качестве оценки рассматривают действительные значения в области
    $\left[ -1, 1\right]$.

    Рассмотрим основные методы вычисления оценочных параметров, на основе которых
    возможно автоматическое создания тональных лексиконов.

        \subsubsection{Вычисление оценки на основе метрики log-likelihood}
        Метод, предложенный в \cite{lexiconLL} предполагает наличие двух корпусов, на основании
        которых вычисляется частотная оценка принадлежности слова к каждому из корпусов.
        В общем случае, под <<словом>> понимается терм предложения, однако
        реальное приминение в \cite{lexiconLL} находит свое место в составлении
        списка частот для определенных частей речи.

        Тем не меннее, в общем случае для подсчета на уровне термов {\it ожидаемой
        степени принадлежности} $E_i(w)$, применяется следующая формула:
        \begin{equation}
            \label{eq:classDifference}
            E_i(w) = \dfrac{N_i\sum\limits_{j=1}^{2}O_i(w)}{\sum\limits_{j=1}^{2}N_i}
        \end{equation}

        Здесь, параметр $i$ является индексом коллекции, $O_j(w)$ -- обозреваемое
        значение, которое соответствует числу вхождений $w$ в корпус $j$, а $N_j$
        -- общее число слов в корпусе $j$.

        Далее, на основании полученных степеней принадлежности терма соответствующему
        классу, применяют метрику log-likelihood для вычисления степени <<важности>>
        терма:
        \begin{equation}
            \label{eq:loglikelihood}
            - \ln \lambda = \sum\limits_i O_i \ln \left( \dfrac{O_i}{E_i} \right)
        \end{equation}

        Если произвести сортировку словаря на основе формулы параметра формулы
        \ref{eq:loglikelihood} в формате убывания значения, то вершину списка
        будут представлять термы $w$, для которых наблюдается большая разница в
        степени принадлежности рассматриваемых корпусов. Соответственно, термы
        с минимальной разницой окажутся в конце отсортированного списка.

        Степень важности терма является положительной величиной. Дополнительно можно
        ввести знаковый параметр на основании разницы между показаниями формулы
        \ref{eq:classDifference} для двух классов.

        \subsubsection{Предсказывание семантической ориентации прилагательных}
        \label{sec:adjectivesPrediction}
        В работе \cite{lexiconAdjectives} рассматривается способ определения
        тональной оценки прилагательных, которые являются аргументами конъюнктов.
        Основой подхода является гипотеза об ограничении ориентации прилагательных
        в зависимости от типа объединяющего из конъюнкта и наличия префиксов отрицаний:
        %В таких лингвистических конструкциях как конъюнкты, связь и ориентация
        %аргументов зависит от способа их соединения:
        \begin{center}
            \it
            Этот бриллиант \underline{красивый} {\bfи} \underline{дорогой}

            Бриллиант \underline{красивый}, {\bfно} \underline{дорогой}

            Это украшение \underline{некрасивое} {\bfи} \underline{дорогое}

            Украшение \underline{некрасивое}, {\bfно} \underline{дорогое}
        \end{center}

        Для построения автоматического извлечения семантически ориентированой
        информации на основе содержимого корпуса большого объема.
        Извлечение и оценка тональности прилагательных, а также связей между ними
        реализуется следующими этапами:
        \begin{enumerate}
            \item Из корпуса выбираются все конъюнкты с релевантными
                морфологическими связями.

                Извлечение конъюнктов выполнялось с помощью формальной
                грамматики, примененной к корпусу из 21 миллиона словоформ.
                В результате было собрано около 15 тысяч пар прилагательных;

            \item Применяется регерессионная модель для объединения информации
                разных конъюнктов с целью определения ориентации каждой из связанных пар.
                Результатом является граф с одинакого либо разноориентированными
                связями между прилагательными;
            \item Разделение прилагательных на две группы с разными ориентациями
                с помощью алгоритма кластеризации. Каждая группа включает в себя
                максимально возможное число прилагательных.
                % 6 (если нужно более подробно)
                Для этого, к построенному графу применяется функция $\Phi$,
                параметром которой является $\mathcal{P}$ -- разбиение множества
                прилагательных на группы $C_1$ и $C_2$:
                \begin{equation}
                    \Phi(\mathcal{P}) = \sum\limits_{i=1}^2 \Bigg( \dfrac{1}{|C_i|} \sum\limits_{x,y \in C_i, \\ x \neq y} d(x,y) \Bigg)
                \end{equation}
                Где $|C_i|$ -- мощность соответствующего класса; $d(x, y)$ --
                степень различия прилагательных $x$ и $y$.
                Далее, осуществляется поиск параметра $\mathcal{P}_{min}$ для
                построения наилучшего разбиения;

            \item Для групп $C_i, \hspace{4pt} i=\overline{1,2}$ вычисляются
                средние частоты упоминания входящих в них прилагательных.
                Та группа, для которой полученное значение наибольшее --
                маркируется как тонально-положительная.
                % 7
                Ранее, в работе \cite{lexiconAdjectivesPrevious} показывается,
                что противопоставление качественным прилагательным (т.е.
                прилагательные противоположной группы) в 81\% случаев оказывается
                семантически неразмеченным. Отмечается, что этот факт демонстрирует
                корелляцию с ориентацией прилагательного, которая наиболее вероятно
                является положительной.
        \end{enumerate}

        Применение описанного выше подхода к задаче классификации конъюнктов
        позволили добиться довольно высоких показаний точности (91\% и выше).
        Отмечается потенциальная возможность применения метода к другим
        частям речи.

        \subsubsection{Вычисление оценки на основе тональности словосочетаний}
        \label{sec:soEvaluation}
        В работе \cite{lexiconSO} предлагается подход который в отличие от
        статьи \cite{lexiconAdjectives}, рассмотренной в п. \ref{sec:adjectivesPrediction},
        применим к любым словосочатаниям. Алогоритм состоит из выполнения следующих шагов:
        \begin{enumerate}
            \item Извлечение {\it синтаксических конструкций}, для которых будет производиться
                дальнейшая оценка. В качестве таких конструкций могут быть фразы, содержащие
                прилагательные или наречия. [Ссылка на предыдущую работу]. В тоже время,
                при извлечении одной лишь части речи может возникнуть проблема нехватки контекста
                для определения оценки. Так, например прилагательное <<непредсказуемость>>
                может иметь как негативную окраску в словосочетании <<непредсказуемое поведение>>,
                так и положительную: <<непредсказуемый сюжет>>.
            %Далее, под термином <<слово>> будем понимать произвольную синтаксическую конструкцию, извлеченную
            %из текста.
            \item Производится оценка извлеченных синтаксических конструкций на основе
                меры взаимной информации ({\it Pointwise Mutation Information, PMI}).
                Вычисление меры производится между двумя словами $word_1$ и $word_2$,
                и определяется следующим образом:
                \begin{equation}
                    \label{eq:pmi}
                    PMI(word_1, word_2) = log_2 \Bigg[ \dfrac{P(word_1 \hspace{4pt} \&\& \hspace{4pt} word_2)}{P(word_1) \cdot P(word_2)} \Bigg]
                \end{equation}

                Где $P(word_1 \hspace{4pt} \&\& \hspace{4pt} word_2)$ -- вероятность
                размещения слов $word_1$ и $word_2$ вместе. Соотношение числителя
                к знаменателю в формуле \ref{eq:pmi} определяет степень зависимость одного
                слова от другого.

                Семантической ориентацией ({\it Semantic Orientation, SO}), для рассматриваемой
                конструкцией называется величина, которая вычисляется на основе
                тональных меркеров $ ``positive\text{''}$ и $``poor\text{''}$, являющихся аргументами
                меры точечной взаимоинформации:
                \begin{equation}
                    \label{eq:so}
                    SO(word) = PMI(word, ``excellent\text{''}) - PMI(word, ``poor\text{''})
                \end{equation}

                Наибольшее значение в формуле \ref{eq:so} достигается в случае
                наличия наибольшей связи рассматриваемой конструкции $phrase$
                с маркером $ ``excellent\text{''}$; наименьшее, в случае наибольшей связи
                с $ ``poor\text{''}$ маркером.

                Формула \ref{eq:pmi} рассматривалась применительно к параметрам
                {\it word}. Для вычисления уравнения \ref{eq:so} от параметра
                $phrase$, используется функция на основе числа совпадений
                $hits(phrase)$, а также оператор {\it NEAR} расположения слов в
                непосредственной близости. В сочетании с формулами \ref{eq:pmi}
                и \ref{eq:so}, семантическая ориентация вычисляется следующим
                образом:
                \begin{equation}
                    \label{eq:soPhrase}
                    SO(phrase) = log \Bigg[ \dfrac{hits(phrase \hspace{4pt} NEAR \hspace{4pt}``excellent\text{''})hits(``poor\text{''}) }{hits(phrase \hspace{4pt}NEAR \hspace{4pt}``poor\text{''})hits(``excellent\text{''})} \Bigg]
                \end{equation}

            \item Для подсчета оценки могут быть использованы формулы \ref{eq:so} и
                \ref{eq:soPhrase}.
        \end{enumerate}

        Эксперименты, проведенные для набора из 410 обзоров с ресурса мнений пользователей {\it Epinions},
    показывают среднюю точность классификации порядка 74\%. Как оказалось, самым
    сложным источником для анализа оказались обзоры на фильмы; на такой коллекции
    точность классификации опустилась до уровня 64\%. Наилучшие показатели были
    достигнуты на коллекциях мнений об автомобилях и банках, на которых точность
    оказалась в пределах 80--84\%.

    \subsection{Подходы к решению задачи тональной классификации с использованием лексиконов}
        % Добавить обзор статей
        \subsubsection{Автоматическое порождение тональных лексиконов}
        В работе \cite{automaticLexiconBuilding} описан способ построения лексикона
        на основе метода <<удаленного контроля>>. В качестве исходных сообщений,
        авторы подхода использовали корпус сообщений сети \twitter, содержащий
        для каждого информации метки мнений ({\it positive} и {\it negative}).
        Такие метки легли в основу обучения контроля полярности классификатора.

        % Описание модели (постановка задачи, раскрытие термина)
        Задача контроля полярности ставится следующим образом. Пусть имеется
        размеченные данные $ \{{\bf x}_i, {\bf y}_i \}_{i=1}^{n}$, на основе
        которых требуется необходимо построить функцию принятия решения
        $f({\bf x}) \to {\bf y}$, которая бы на основе входных параметров
        определяла бы результирующую метку сообщения.
        В частности, авторы использовали линейную модель SVM классификатора, с
        функцией предсказания следующего вида:
        \begin{equation}
            f = sign(w^T{\bf x} + b)
        \end{equation}

        Где $w$ -- весовые коэффициенты, полученные на основе обучающей коллекции;
        $b$ -- поправочный коэффициент.

        % Алгоритм построения модели
        Авторы статьи предлагают следующий подход автоматического построения
        лексикона и его использования для создания классификационной модели:
        \begin{enumerate}
            \item Составление неразмеченного корпуса сообщений сети \twitter $C$.
            \item Для каждого сообщения $t_i \in C$ использовать подсказки
                (хэштеги, эмотиконы) для получения метки ({\it positive} и {\it negative})
                $y_i \in \{-1; +1\}$. Использование эмотиконов вида <<:-)>>, <<:-(>>
                в качестве иникатора выражения автора сообщения в целом.
            \item Извлечение биграмм и униграмм особенности сообщения $t_i$ в
                вектор ${\bf x}_i \in R^{|L|}$, где $L$ -- лексикон, состоящий из
                термов формата биграмм и униграмм;
            \item Построить классификациюнную модель ${\bf w}$ на основе корпуса
                $C = \{{\bf x}_i, {\bf y}_i \}_{i=1}^{N}$ следующим образом:
            \begin{equation}
                {\bf w} = \sum\limits_{i=1}^{N}\alpha_i y_i {\bf x}_i
            \end{equation}
            Здесь ${\bf x}_i$ выступают в качестве опорных векторов; $y_i$ -- их метки;
            $\alpha_i$ -- параметр краевой задачи, который вносит вклад в
            $w$ в случае когда положителен.
            \item Каждый компонент $w_j$ обученной модели $w$, соответствует компоненту $l_i$
                лексикона $L$, что устанавливает связи с ассоциативной оценкой.
        \end{enumerate}

        % Алгоритм постоения лексикона
        Используемый лексикон составлен на основе \twitter корпуса {\it Emoticon140}.
        Метки для корпуса расставлялись на основе эмотиконов, содержащихся в
        тексте сообщений.
        Так, сообщения содержащие эмотиконы типа <<:)>> считались положительными,
        а <<:(>> -- отрицательными.
        Объем корпуса составляет $1.6$ млн. сообщений с одинаковым распределением
        положительных и негативных сообщений.

        Для составления лексикона используется подход на основе вычисления
        точечной меры взаимоинформации (см. п. \ref{sec:soEvaluation}).
        Дополнительно авторами были составлены собственные лексиконы: MPQA, BingLiu, NRC.
        На этапе предварительного тестирования и настроки модели, отмечается прирост
        качества при увеличении числа используемых лексиконов.

        % Результаты
        Подход демонстрирует хорошие результаты качества работы классфикационной
        модели. На соревнованиях {\it Semeval-2014} такой подход занял второе
        место.
        Применительно к коллекциям $SMS$ и $Twitter$, оценка качества работы на
        основе $F-$меры колеблется в диапазоне 66.8 -- 71\%.

        \subsubsection{<<State-of-the-art>> подход к решению задачи
            сентиментального анализа (Saif M. Mohammad, Svetlana Kiritchenko, Xiaodan Zhu)}

        Статья \cite{modernApproach} предлагает способы построения {\it SVM}
        классификаторов для решения следующих задач классификации:
        \begin{itemize}
            \item Определения тональной оценки для всего сообщения в целом;
            \item Выявления тональности термов сообщения.
        \end{itemize}

        % Описание подхода (только для случая оценки сообщения в целом)
            % Идея с автоматической генерацией лексикона
        Ключевой идеей повышения качества классификации являются лексиконы,
        которые созданы автоматически на основе коллекции сети \twitter.
        Для этого, авторы разделили все сообщения корпуса на тональные классы с
        помощью такой метаинформации в сообщениях, как хэштеги.
        Для этого были составлены два множества хэштегов: {\it positive} и
        {\it negative}.

        Объем коллекции, на основе которой составлен лексикон, составляет $775$
        тыс. сообщений. Для распределения сообщений на классы, авторы использовали
        следующую логику:
        \begin{enumerate}
            \item Если в сообщении встречался хотя бы один хэштег из множества positive, то
                сообщение считается положительным;
            \item Если в сообщении встречается хотя бы один хэштег из negative множества, то
                сообщение считается отрицательным.
        \end{enumerate}

        Для построения лексиконов, авторы использовали метод <<тональности словосочетаний>>
        (см. п. \ref{sec:soEvaluation}, формула \ref{eq:so}) \cite{lexiconSO}.

        В качестве классфикатора, авторы использовали SVM с линейным ядром, и
        параметром штрафной функции $C = 5\cdot 10^{-3}$.
        Векторизация сообщения включала в себя набор дополнительных признаков.
        Перечислим некоторые из них (полный список представлен в \cite{modernApproach}):
        % Используемые признаки
        \begin{itemize}
            \item {\bf Учет регистра:} количество слов, записанных в верхнем регистре;
            \item {\bf Учет хэштегов:} число входящих в сообщение хэштегов (слов с префиксом <<\#>>);
            \item {\bf Символьные $n$-граммы:} присутствие или отсутствие последовательности
                подряд идущих одинаковых символов длиной в 3, 4, и 5 символов;
            \item {\bf На основе лексиконов:} признаки, созданные на основе каждого из
                лексиконов ($w$ -- рассматриваемый токен, $p$ -- полярность)  % функции
                \begin{itemize}
                    \item Число токенов, для которых выполнено: $score(w, p) > 0$;
                    \item Суммарное значение $\sum_{w \in tweet} score(w,p)$;
                    \item Вычисление максимума $\max_{w \in tweet} score(w,p)$;
                    \item Учет оценки последнего токена, при условии: $score(w,p) > 0$.
                \end{itemize}

            \item {\bf Удлиненные слова:} число слов, в которых символ повторяется болле
                двух раз, например <<sooooo>>;
            \item {\bf Суффикс отрицания:} добавляет к слову суффикс {\it \_NEG}, в
                случае, если перед ним имеется конструкция 'Отрицание + знак пунктуации'.
                Под отрицанием понимаются слова вида: {\it no}, {\it shouldn't}.
                В качестве знаков пунктуации рассматриваются символы:
                <<,>>, <<.>>, <<:>>, <<;>>, <<!>>, <<?>>.
                Пример:
                \begin{center}
                    \it
                    \underline{shouldn't,} perfect \\
                    perfect\_NEG
                \end{center}
        \end{itemize}

        % Добавление тональных префиксов

            % Используемые особенности

        % Результаты





    \subsection{Оценка качества классификационной модели}
    % Посмотреть обзоры из обзора соревнований.

        \subsubsection{Точность и полнота}
    Чтобы произвести оценку качества работы классификатора на некотором наборе
    сообщений, необходимо чтобы для этого набора существовали эталонные
    значения. Применительно к задаче тональной классификации, под значениями
    понимается класс, к которому необходимо отнести соответствующее сообщение.

    Таким образом, для каждого сообщения ответ может быть получен как со стороны
    классификатора, так и группой экспертов. Все возможные случаи ответов
    для фиксированного класса $A$ удобнее всего представить в таблице
    \ref{table:contingent}. Такое представление носит название
    {\it таблицы контингентности}.

    \begin{table}[H]
        \centering
        \caption{Таблица контингентности для класса $A$}
        \label{table:contingent}
        \begin{tabular}{|c|c|c|c|}
            \hline
            \multicolumn{2}{|c|}{\multirow{2}{*}{Принадлежность cообщений к классу $A$}} &     \multicolumn{2}{c|}{эксперты}                     \\ \cline{3-4}
            \multicolumn{2}{|c|}{}                                              &   положительная             & отрицательная                           \\ \hline
            \multirow{2}{*}{классификатор}          & положительная             & {\cellcolor[HTML]{9AFF99} $TP$} & {\cellcolor[HTML]{FFCCC9} $FP$}     \\ \cline{2-4}
                                                    & отрицательная             & {\cellcolor[HTML]{FFCCC9} $FN$} & {\cellcolor[HTML]{9AFF99} $TN$}     \\ \hline
        \end{tabular}
     \end{table}

     На основе таблицы \ref{table:contingent} можно рассчитать следующие
     характеристики качества работы классификатора для соответсвующего класса:
    \begin{itemize}
        \item {\bf полнота} -- число найденных сообщений, которые
            действительно принадлежат соответствующему классу относительно всех
            сообщений соответсвующего класса:

            \begin{equation}
                \label{eq:recall}
                R_A = \dfrac{TP}{TP + FN} \hspace{20pt}
            \end{equation}

        \item {\bf точность} -- количество сообщений, которое
            классификатор правильно отнес к соответсвующему классу по отошению
            ко всему объему сообщений определенных системой в этот класс:

            \begin{equation}
                \label{eq:precision}
                P_A = \dfrac{TP}{TP + FP} \hspace{20pt}
            \end{equation}
    \end{itemize}

        на практике возникает необходимость в метрике, которая бы позволяла одновременно
    обе характеристики: точность и полноту. для этого предусмотрена $f-мера$, которая
    в общем случае вычисляется по формуле:
    \begin{equation}
        \label{eq:fmeasurecommon}
        f(\beta) = \dfrac{(1+\beta^2) P \cdot R}{\beta^2 \cdot P + R}
    \end{equation}

    в случае, если $\beta = 1$, то формула \ref{eq:fmeasurecommon} преобразуется
    к гармоническому среднему:
    \begin{equation}
        \label{eq:fmeasure}
        F_1 = \dfrac{2 \cdot P R}{P + R}
    \end{equation}

    \subsubsection{$F_1-micro$ и $F_1-macro$ меры качества}
    Рассмотрим случай, когда необходимо рассмотреть параметры качества работы
    классификатора относительно нескольких классов одновременно.
    Пусть имеется $K$ классов, относительно которых будут вычисляться параметры
    полноты, точности, и F-меры.
    Отностельно каждого класса можно составить таблицы контингентности,
    аналогичные таблице \ref{table:contingent}.

    одним из методов вычисления среднего значения параметров точности и полноты,
    является {\it микроусреднение} \cite{micromacromeasures}:
    \begin{itemize}
        \item {\it микроусреднением полноты} --- является обобщением формулы
            \ref{eq:recall} на случай нескольких классов:
            \begin{equation}
                R_{micro_{(1, \ldots, N)}} = \dfrac{\sum\limits_{i=1}^N TP_i}{\sum\limits_{i=1}^N TP_i + \sum\limits_{i=1}^N FP_i}
            \end{equation}
        \item {\it микроусреднением точности} --- называется обобщением формулы
            \ref{eq:precision} на случай нескольких классов:
            \begin{equation}
                P_{micro_{(1, \ldots, N)}} = \dfrac{\sum\limits_{i=1}^N TP_i}{\sum\limits_{i=1}^N TP_i + \sum\limits_{i=1}^N FN_i}
            \end{equation}
    \end{itemize}

%    далее, подставляя параметры $P_{micro}$, $P_{macro}$ в формулу \ref{eq:fmeasure},
%    получим {\it микроусредненную меру $F_1$}:

    Другой метод усреднения значений полноты и точности называется {\it макроусреднением} \cite{micromacromeasures}.
    параметры на основе такого подхода, вычисляются следующим образом:
    \begin{itemize}
        \item {\it макроусреднение полноты} --- вычисление среднего значения параметров
            полноты каждого из классов:
            \begin{equation}
                R_{macro_{(1, \ldots, N)}} = \dfrac{\sum\limits_{i=1}^N R_i}{N}
            \end{equation}
        \item {\it макроусреднение точности} --- вычисление среднего значения параметров
            точности каждого из классов:
            \begin{equation}
                P_{macro_{(1, \ldots, N)}} = \dfrac{\sum\limits_{i=1}^N P_i}{N}
            \end{equation}
    \end{itemize}

    Таким образом, на основе каждого из метода усреднений может быть вычислена
    $F_1$ мера:
    \begin{equation}
        \label{eq:fmacro12}
        F_{1_{macro_{(1, \ldots, N)}}} = \dfrac{2 \cdot P_{macro_{(1,\ldots, N)}} R_{macro_{(1,\ldots, N)}} }{P_{macro_{(1,\ldots, N)}} + R_{macro_{(1,\ldots, N)}}}
    \end{equation}
    \begin{equation}
        \label{eq:fmicro12}
        F_{1_{micro_{(1, \ldots, N)}}} = \dfrac{2 \cdot P_{micro_{(1,\ldots, N)}} R_{micro_{(1,\ldots, N)}} }{P_{micro_{(1,\ldots, N)}} + R_{micro_{(1,\ldots, N)}}}
    \end{equation}

    % про ф-меру сюда же

    Мaкроусреднение придает одинаковый вес каждому из усредняемых классов, в то
    время как при микроусреднении вес учитывается на основе числа документов в
    классе. поскольку $F_{macro}$ мера игнорирует параметр $TN$, то смещение
    среднего значения будет производиться в сторону того класса, для которого классификатор сработал
    лучше (большее значение $TP$); в тоже время, при использовании $F_{micro}$,
    смещение будет произведено в сторону наибольшего класса. \cite{micromacromeasures}

    Таким образом, результаты полученные на основе микроусреднения являются мерой
    эффективности на коллекциях большого объема. для получения аналогичного эффекта
    на коллекциях малого объема, необходимо использовать макроусреднение. \cite{micromacromeasuresdifferences}

    \subsection{Соревнования в области тональной классификации сообщений}
    \label{sec:tonalityCompetition}
    % цель задачи
    За последние несколько лет, в области автоматической обработки текстовых сообщений
    активно набирает популярность платформа открытого тестирования систем
    тонального анализа русскоязычных сообщений {\it SentiRuEval} \cite{tonalityanalisys}.
    тестирование проводится в формате соревнований, к которым организаторы заранее подготавливают
    коллекции данных. Данные представляют собой сообщения сети \twitter, каждое из которых
    выражает положительное либо негативное мнение автора по отношению к рассматриваемой
    в собщении организации. Среди предментных областей доступны следующие коллекции
    данных:
    \begin{itemize}
        \item Сообщения о банковских компаниях;
        \item Сообщения о телекоммуникационных компаниях.
    \end{itemize}

    Тональная классификация заключается в определении оценки по отношению к
    рассматриваемой в сообщении компании. сообщения, для которых пользователям
    необходимо проставить оценку, представляются в {\it тестовой коллекции}. Изначально все
    сообщения тестовой коллекции отмечены как <<нейтральные>>, и имеют оценку <<0>>.
    Участнику предлагается изменить значение оценки на <<1>> если отношение к
    рассматриваемой организации <<положительное>>, или на <<-1>> в случае
    <<негативного>> отношения.

    % про коллекции (почему они несбалансированы, процентное соотношение твитов)

    Помимо тестовых коллекций, организаторы также подготавливают {\it обучающие} и
    {\it эталонные} коллекции для каждой из областей. последние, в свою очередь,
    доступны после окончания соревнований. данные для коллекций собираются на
    основе {\it streaming api twitter}. Отмечается, что при сборе данных отсутствует
    искусственное завышение классов с малым числом сообщений \cite{tonalityanalisys}.
    так, во всех предметных областях преобладают сообщения с нейтральной оценкой (см. таблицы
    \ref{table:trainTableStat} и \ref{table:testTableStat}).

    \begin{table}[h]
        \centering
        \caption{Распределение объемов классов сообщений в обучающих коллекциях}
        \label{table:trainTableStat}
        \begin{tabular}{|c|c|c|c|}
            \hline
            Oбласть     & Нейтральные \%    & Тональные  \%     & Число сообщений \cite{dialog2015} \\ \hline
            TKK        & 47,59              & 52,42             &   \~ 4\hspace{3pt}800\\ \hline
            Banks      & 58,35              & 41,65             &   \~ 4\hspace{3pt}900\\ \hline
        \end{tabular}
     \end{table}

    \begin{table}[h]
        \centering
        \caption{Распределение объемов классов сообщений в тестовых коллекциях}
        \label{table:testTableStat}
        \begin{tabular}{|c|c|c|}
            \hline
            Oбласть     & Нейтральные \%    & Тональные  \%     \\ \hline
             TKK        & 67,70             & 32,30             \\ \hline
             Banks      & 77,90             & 22,10             \\ \hline
        \end{tabular}
     \end{table}
    % система оценки (метрики, используемые для оценки классификационной модели)
    Для {\it оценки качества} классификатора, используются макро- и микроусреднения
    $F_1$-меры для классов положительных и негативных сообщений. Вычисление
    $F_{macro(pos, neg)}$ и $F_{micro(pos, neg)}$ производится на основе
    формул \ref{eq:fmacro12} и \ref{eq:fmicro12} соответственно. нейтральный
    класс сообщения в оценке не участвует. однако в случае, если классификатор
    некорректно определяет тональное сообщение, то это выявляется в расхождении
    мнения классификатора и эксперта в таблицах контингентностей, составленных для
    классов $pos$ и $neg$, на основании которых высчитываются параметры полноты
    и точности.

    % Результаты
    Результаты участников сравниваются относительно нижнего порогового значения -- {\it baseline}.
    В качестве такого порога рассматривается классификатор, который для каждого
    сообщения проставляет тональную оценку наиболее частотного класса. В таблицах
    \ref{table:exampleResultsBanks} и \ref{table:exampleResultsTTK} рассматривается
    прогоны, демонстрирующие лучшие результаты в сравненнии с нижним пороговым
    значением. Параметры прогонов следующие \cite{tonalityanalisys}:
    \begin{enumerate}
        \item Классификатор {\it SVM}, с учетом признаков:
            нормализованные леммы, установление связи между леммами;
        \item Метод максимальной энтропии с учетом признаков:
            n-граммы (слов и символьные), дополнительные результаты моделирования;
        \item Классификатор {\it SVM} c учетом: n-граммы (словесные и буквенные),
            знаки пунктуации, наличие ссылок, символы <<ретвита>>, использование
            эмоционально окрашенного словаря.
    \end{enumerate}

    \begin{table}[H]
        \centering
        \caption{Результаты качества работы лучшего прогона в сравнении с {\it baseline}.
        {\it SentiRuEval-2015}, колекция сообщений о банках}
        \label{table:exampleResultsBanks}
        \begin{tabular}{|c|c|c|}
        \hline
        №                       &       $F_{macro(pos, neg)}$        & $F_{micro(pos, neg)}$  \\ \hline
        baseline                &           0.1267                      &       0.2377              \\ \hline \hline
        1                       &           0.3354                      &       0.3656              \\ \hline
        2                       &           0.3598                      &       0.3430              \\ \hline
        3                       &           0.3520                      &       0.3370              \\ \hline
        \end{tabular}
     \end{table}

     \begin{table}[H]
        \centering
        \caption{Результаты качества работы лучшего прогона в сравнении с {\it baseline}.
        {\it SentiRuEval-2015}, колекция телекоммуникационных сообщений}
        \label{table:exampleResultsTTK}
        \begin{tabular}{|c|c|c|}
        \hline
        №                       &       $F_{macro(pos, neg)}$        & $F_{micro(pos, neg)}$  \\ \hline
        baseline                &           0.1823                      &       0.3370              \\ \hline \hline
        1                       &           0.4882                      &       0.5355              \\ \hline
        2                       &           0.4670                      &       0.5060              \\ \hline
        3                       &           0.4477                      &       0.5282              \\ \hline
        \end{tabular}
     \end{table}

    % Анализ (почему наблюдается разница в результатах между задачами)
    Как можно заметить, показания таблиц \ref{table:exampleResultsBanks} и \ref{table:exampleResultsTTK}
    демонструют значительную разницу в максимумах для каждого из прогонов двух областей.
    Для выявляения причины, вызвавшей такое расхождение, в \cite{tonalityanalisys}
    проводится подсчет разницы между обучающей и тестовых коллекцией для каждой из
    областей на основе:
    \begin{itemize}
        \item Несимметричная мера удаленности -- дивергенция Кульбака-Лейблера;
        \item Симметричная мера Йенсена-Шеннона.
    \end{itemize}

    Результaты показали, что наибольшее расхождение между коллекциями наблюдалось в
    области банков.

    Такое расхождение может быть объяснено тем, что коллекции для каждой из областей
    были подготовлены в разные периоды времени. Обучающие коллекции составлены в
    период июнь-август 2014 года, в момент разгара боевых действий на Украине.
    В тоже время, данные для тестовых коллекций были получены {\it на пол года раньше}, в период с
    декабря 2013 по февраль 2014.

    % Ориентация на анализ
    Несмотря на то, что в сообщениях могло упоминаться отношение к нескольким
    компаниям одновременно, большинство участников все равно предпочли
    оценивать сообщение в целом. Участники с такой стратегией показали
    более высокие результаты чем те, кто пытался производить оценку для каждой
    компании в отдельности. Отсюда можно сделать вывод, что на сегодняшний момент
    задача по тональной оценке отдельных объектов сообщения является весьма
    ограниченной \cite{tonalityanalisys}.
