\newpage
\section{Обзор предметной области}
    % Объяснить, какие подходы к классификации рассматриваются в этой области.
    На сегодняшний день, большинство пользователей крупных социальных сетей,
    таких как Twitter, предпочитают высказывать свои отзывы и мнения о товарах
    и услугах в формате коротких сообщений. Возможность быстрого реагирования
    на сообщения со стороны компаний, предоставляемых эти услуги, возможно лишь
    в случае их автоматической обработки.

    Как известно, одним из направлений в решении задачи классификации является
    использование методов машинного обучения. Ввиду существенного роста объема
    доступной информации социальных сетей, такие проблемы как адаптация и
    обучение классификационных моделей становятся все менее значительными.
    В связи с этим, рассмотрим наиболее популярные методы машинного обучения \cite{svmAdvantages},
    которые находят свое применение к задачи тональной классификации сообщений.

    \subsection{Подходы к тональной классификации на основе методов машинного обучения}
        Основой работы рассматриваемых методов является представление исходных
        сообщений $m$ в формате вектора нормализованых слов $\{f_1, f_2, \ldots, f_n\}$.
        В качеcтве значений каждой из размерности вектора $\vec{m}$ можно сопоставить
        $n_{f_i}(m)$ -- число вхождений терма $f_i$ в рассматриваемое сообщение $m$.
        Такая модель является вариацией {\it Bag Of Words} \cite{svmAdvantages}.
        В результате, сообщение $m$ представляет собой вектор:
        \begin{equation}
            \vec{m} = (n_1(m), n_2(m), \ldots, n_k(m)) \nonumber
        \end{equation}

        \subsubsection{Метод <<Наивного Байеса>>}
        % На основе статьи
        Один из подходов к класификации сообщений заключается в определении класса $c^{*}$,
        к которому относится рассматриваемое сообщение $m$ на основе метрики
        {\it максимального правдоподобия}:
        \begin{equation}
            c^{*} = argmax_c \hspace{2pt} P(c|m) \nonumber
        \end{equation}

        В основе вычисления условной вероятности $P(c|m)$ лежит правило Байеса:
        \begin{equation}
            \label{eq:BayesRule}
            P(c|m) = \dfrac{P(c, m)}{P(m)} = \dfrac{P(c)\cdot P(m|c)}{P(m)}
        \end{equation}

        Классификатор, построенный на основе правила, представленного в
        формуле \ref{eq:BayesRule}, называется {\it NB}-классификатором.
        Для оценки условной вероятности в формуле \ref{eq:BayesRule}, предполагается
        независимость термов сообщения, и вычисляется следующим образом:
        \begin{equation}
            P_{NB} (c|m) = \dfrac{P(c)\cdot(\Pi_{i=1}^{n}P(f_i|c)^{n_i(m)})}{P(m)} \nonumber
        \end{equation}

        Несмотря на простоту реализации алгоритма, независимость термов $f_i$ сообщения
        является ограничением для достижения реального правдоподобия. Работа \cite{nbAdvantages}
        демонстрирует оптимальность метода Наивного Байеса для большинства задач
        классификации, в которых присутствуют признаки, позволяющие установить
        тесную связь с соответствующими классами. В тоже время, использование
        более сложных методов позволяет добиться лучших результатов.

        %\subsubsection{Метод <<Максимальной энтропии>>}
        % Из статьи
        \subsubsection{Метод <<Опорных векторов>>}
        % 9.1.2
        В отличие от метода <<Наивного Байеса>>, подход на основе рассматриваемого
        метода предполагает поиск гиперплоскости, разделяющей сообщения разных классов.
        Построение выполняется на этапе обучения модели. На этом этапе решается задача
        поиска нормали $\vec{w}$ к гиперплоскости, причем разбиение классов должно
        производиться с максимально возможным отступом.

        Для поиска нормали составляется {\it оптимизационная задача с граничными
        условиями}:
        \begin{equation}
            \label{eq:optimizationSVM}
            \vec{w} = \sum_{j=1}^{N} \alpha_i c_i \vec{m_i}, \hspace{2pt} \alpha_i \geq 0
        \end{equation}

        В уравнении \ref{eq:optimizationSVM}, коэффициент $c_i \in \{-1, 1\}$
        указывает на принадлежность сообщения $m_i$ соответствующему классу;
        $\alpha_i$ -- коээфициент решения задачи двойной оптимизации. Среди всех
        векторов $\vec{m}$, для которых выполнено условие $\alpha_i > 0$, называются <<опорными>>.
        Определения класса, к которому относится рассматриваемый документ, осуществляется
        на основе стороны гиперплоскости, на которую падает проекция вектора $\vec{m}$.

        В общем случае, классификатор построенный на рассматриваемом подходе,
        позволяет достичь лучших резульатов классификации если сравнивать с
        аналогом на основе метода <<Наивного Байеса>> \cite{svmCompareVsNB}.

        (Дополнить на основе аналогичного раздела из \cite{islr})

        % SVM with multiple classes
    \subsection{Признаки, используемые для классификации сообщений}
        % Лемматизация термов сообщения на основе метрик
        \subsubsection{Векторизация сообщений}
        % bag of words

        % tf-idf
        % tf-idf + вспомогательный словарь.
        \subsubsection{Вспомагательные признаки для сообщений}
        %

    \subsection{Способы построения тональных лексиконов}

    В любом предложении естественного языка, содержатся ключевые слова ( и словосочетания),
    на основании которых можно извлечь дополнительную информацию. Если рассматривать
    предложение с точки зрения тонального анализа, то некоторые слова могут
    придавать негативную или положительную окраску всему сообщению в целом.
    В связи с этим, умение точно извлекать тональные слова или словосочетания
    с целью составления дополнительной метаинформации о предложении (сообщении),
    может оказать положительное влияние на качество классификации.

    Можно сказать, что возникает необходимость в словаре, состоящего из пар
    $<w, t>$, где $w$ -- слово или словосочетание, а $t$ -- его оценка.
    Словарь, представленный в таком формате называется {\it лексиконом}.
    Задача, которую решает лексикон в области тонального анализа -- сопоставление
    тональной окраски для каждого слова содержащегося в нем.
    Очевидно, что формализация оценочного параметра приводит к представлению
    параметра $t$ в формате числового значения, возможно с учетом знака.
    Обычно в качестве оценки рассматривают действительные значения в области
    $\left[ -1, 1\right]$.

    Рассмотрим основные методы вычисления оценочных параметров, на основе которых
    возможно автоматическое создания тональных лексиконов.

        \subsubsection{Вычисление оценки на основе метрики {\it log-likelihood}}
        Метод, предложенный в \cite{lexiconLL} предполагает наличие двух корпусов, на основании
        которых вычисляется частотная оценка принадлежности слова к каждому из корпусов.
        В общем случае, под <<словом>> понимается терм предложения, однако
        реальное приминение в \cite{lexiconLL} находит свое место в составлении
        списка частот для определенных частей речи.

        Тем не меннее, в общем случае для подсчета на уровне термов {\it ожидаемой
        степени принадлежности} $E_i(w)$, применяется следующая формула:
        \begin{equation}
            \label{eq:classDifference}
            E_i(w) = \dfrac{N_i\sum\limits_{j=1}^{2}O_i(w)}{\sum\limits_{j=1}^{2}N_i}
        \end{equation}

        Здесь, параметр $i$ является индексом коллекции, $O_j(w)$ -- обозреваемое
        значение, которое соответствует числу вхождений $w$ в корпус $j$, а $N_j$
        -- общее число слов в корпусе $j$.

        Далее, на основании полученных степеней принадлежности терма соответствующему
        классу, применяют метрику log-likelihood для вычисления степени <<важности>>
        терма:
        \begin{equation}
            \label{eq:loglikelihood}
            - \ln \lambda = \sum\limits_i O_i \ln \left( \dfrac{O_i}{E_i} \right)
        \end{equation}

        Если произвести сортировку словаря на основе формулы параметра формулы
        \ref{eq:loglikelihood} в формате убывания значения, то вершину списка
        будут представлять термы $w$, для которых наблюдается большая разница в
        степени принадлежности рассматриваемых корпусов. Соответственно, термы
        с минимальной разницой окажутся в конце отсортированного списка.

        Степень важности терма является положительной величиной. Дополнительно можно
        ввести знаковый параметр на основании разницы между показаниями формулы
        \ref{eq:classDifference} для двух классов.

        \subsubsection{Вычисление оценки на основе тональности словосочетаний}
        Другой подход к вычислению оценки, применительно к тональной классификации
        предложен в работе \cite{lexiconSO}. %Пусть имеется два корпуса с сообщениями.
        Алогоритм состоит из выполнения следующих шагов:
        \begin{enumerate}
            \item Извлечение {\it синтаксических конструкций}, для которых будет производиться
                дальнейшая оценка. В качестве таких конструкций могут быть фразы, содержащие
                прилагательные или наречия. [Ссылка на предыдущую работу]. В тоже время,
                при извлечении одной лишь части речи может возникнуть проблема нехватки контекста
                для определения оценки. Так, например прилагательное <<непредсказуемость>>
                может иметь как негативную окраску в словосочетании <<непредсказуемое поведение>>,
                так и положительную: <<непредсказуемый сюжет>>.
            %Далее, под термином <<слово>> будем понимать произвольную синтаксическую конструкцию, извлеченную
            %из текста.
            \item Производится оценка извлеченных синтаксических конструкций на основе
                меры взаимной информации ({\it Pointwise Mutation Information, PMI}).
                Вычисление меры производится между двумя словами $word_1$ и $word_2$,
                и определяется следующим образом:
                \begin{equation}
                    \label{eq:pmi}
                    PMI(word_1, word_2) = log_2 \Bigg[ \dfrac{P(word_1 \hspace{4pt} \&\& \hspace{4pt} word_2)}{P(word_1) \cdot P(word_2)} \Bigg]
                \end{equation}

                Где $P(word_1 \hspace{4pt} \&\& \hspace{4pt} word_2)$ -- вероятность
                размещения слов $word_1$ и $word_2$ вместе. Соотношение числителя
                к знаменателю в формуле \ref{eq:pmi} определяет степень зависимость одного
                слова от другого.

                Семантической ориентацией ({\it Semantic Orientation, SO}), для рассматриваемой
                конструкцией называется величина, которая вычисляется на основе
                тональных меркеров $ ``positive\text{''}$ и $``poor\text{''}$, являющихся аргументами
                меры точечной взаимоинформации:
                \begin{equation}
                    \label{eq:so}
                    SO(word) = PMI(word, ``excellent\text{''}) - PMI(word, ``poor\text{''})
                \end{equation}

                Наибольшее значение в формуле \ref{eq:so} достигается в случае
                наличия наибольшей связи рассматриваемой конструкции $phrase$
                с маркером $ ``excellent\text{''}$; наименьшее, в случае наибольшей связи
                с $ ``poor\text{''}$ маркером.

                Формула \ref{eq:pmi} рассматривалась применительно к параметрам
                {\it word}. Для вычисления уравнения \ref{eq:so} от параметра
                $phrase$, используется функция на основе числа совпадений
                $hits(phrase)$, а также оператор {\it NEAR} расположения слов в
                непосредственной близости. В сочетании с формулами \ref{eq:pmi}
                и \ref{eq:so}, семантическая ориентация вычисляется следующим
                образом:
                \begin{equation}
                    \label{eq:soPhrase}
                    SO(phrase) = log_2 \Bigg[ \dfrac{hits(phrase \hspace{4pt} NEAR \hspace{4pt}``excellent\text{''})hits(``poor\text{''}) }{hits(phrase \hspace{4pt}NEAR \hspace{4pt}``poor\text{''})hits(``excellent\text{''})} \Bigg]
                \end{equation}

            \item Для подсчета оценки могут быть использованы формулы \ref{eq:so} и
                \ref{eq:soPhrase}.
        \end{enumerate}

    \subsection{Оценка качества классификационной модели}
    % Посмотреть обзоры из обзора соревнований.

        \subsubsection{Точность и полнота}
    Чтобы произвести оценку качества работы классификатора на некотором наборе
    сообщений, необходимо чтобы для этого набора существовали эталонные
    значения. Применительно к задаче тональной классификации, под значениями
    понимается класс, к которому необходимо отнести соответствующее сообщение.

    Таким образом, для каждого сообщения ответ может быть получен как со стороны
    классификатора, так и группой экспертов. Все возможные случаи ответов
    для фиксированного класса $A$ удобнее всего представить в таблице
    \ref{table:contingent}. Такое представление носит название
    {\it таблицы контингентности}.

    \begin{table}[ht]
        \centering
        \caption{Таблица контингентности для класса $A$}
        \label{table:contingent}
        \begin{tabular}{|l|}
            \hline
             \\ \hline
         \end{tabular}
     \end{table}

     На основе таблицы \ref{table:contingent} можно рассчитать следующие
     характеристики качества работы классификатора для соответсвующего класса:
    \begin{itemize}
        \item {\bf Полнота} -- число найденных сообщений, которые
            действительно принадлежат соответствующему классу относительно всех
            сообщений соответсвующего класса:

            \begin{equation}
                \label{eq:recall}
                R_A = \dfrac{TP}{TP + FN} \hspace{20pt}
            \end{equation}

        \item {\bf Точность} -- количество сообщений, которое
            классификатор правильно отнес к соответсвующему классу по отошению
            ко всему объему сообщений определенных системой в этот класс:

            \begin{equation}
                \label{eq:precision}
                P_A = \dfrac{TP}{TP + FP} \hspace{20pt}
            \end{equation}
    \end{itemize}

        На практике возникает необходимость в метрике, которая бы позволяла одновременно
    обе характеристики: точность и полноту. Для этого предусмотрена $F-мера$, которая
    в общем случае вычисляется по формуле:
    \begin{equation}
        \label{eq:fmeasureCommon}
        F(\beta) = \dfrac{(1+\beta^2) P \cdot R}{\beta^2 \cdot P + R}
    \end{equation}

    В случае, если $\beta = 1$, то формула \ref{eq:fmeasureCommon} преобразуется
    к гармоническому среднему:
    \begin{equation}
        \label{eq:fmeasure}
        F_1 = \dfrac{2 \cdot P R}{P + R}
    \end{equation}

    \subsubsection{$F_1-micro$ и $F_1-macro$ меры качества}
    Рассмотрим случай, когда необходимо рассмотреть параметры качества работы
    классификатора относительно нескольких классов одновременно.
    Пусть имеется два класса, относительно которых будут вычисляться параметры полноты, точности,
    и F-меры.
    Oтностельно каждого класса можно составить таблицы контингентности,
    аналогичные таблице \ref{table:contingent}.

    Одним из методов вычисления среднего значения параметров точности и полноты,
    является {\it микроусреднение} \cite{microMacroMeasures}:
    \begin{itemize}
        \item {\it Микроусреднением полноты} --- называется величина, которая
            вычисляется аналогично формуле \ref{eq:recall}, только на основании
            двух классов:
            \begin{equation}
                R_{micro_{(1, 2)}} = \dfrac{TP_{1} + TP_{2}}{TP_{1} + TP_{2} + FP_{1} + FP_{2}} \nonumber
            \end{equation}
        \item {\it Микроусреднением точности} --- называется величина,
            которая вычисляется аналогично формуле \ref{eq:precision},
            на основании двух классов:
            \begin{equation}
                P_{micro_{(1, 2)}} = \dfrac{TP_{1} + TP_{2}}{TP_{1} + TP_{2} + FN_{1} + FN_{2}} \nonumber
            \end{equation}
    \end{itemize}

%    Далее, подставляя параметры $P_{micro}$, $P_{macro}$ в формулу \ref{eq:fmeasure},
%    получим {\it микроусредненную меру $F_1$}:

    Другой метод усреднения значений полноты и точности называется {\it макроусреднением} \cite{microMacroMeasures}.
    Параметры на основе такого подхода, вычисляются следующим образом:
    \begin{itemize}
        \item {\it Макроусреднение полноты} --- вычисление средних значений параметров
            полноты на основе каждого из классов:
            \begin{equation}
                R_{macro_{(1, 2)}} = \dfrac{R_{1} + R_{2}}{2} \nonumber
            \end{equation}
        \item {\it Макроусреднение точности} --- вычисление средних значений параметров
            точности, вычисленных отдельно на основе каждого из классов:
            \begin{equation}
                P_{macro_{(1, 2)}} = \dfrac{P_{1} + P_{2}}{2} \nonumber
            \end{equation}
    \end{itemize}

    Таким образом, на основе каждого из метода усреднений может быть вычислена
    $F_1$ мера:
    \begin{gather*}
        F_{1_{macro_{(1,2)}}} = \dfrac{2 \cdot P_{macro_{(1,2)}} R_{macro_{(1,2)}} }{P_{macro_{(1,2)}} + R_{macro_{(1,2)}}} \nonumber \\
        \\
        F_{1_{micro_{(1,2)}}} = \dfrac{2 \cdot P_{micro_{(1,2)}} R_{micro_{(1,2)}} }{P_{micro_{(1,2)}} + R_{micro_{(1,2)}}} \nonumber
    \end{gather*}

    % Про ф-меру сюда же

    Мaкроусреднение придает одинаковый вес каждому из усредняемых классов, в то
    время как при микроусреднении вес учитывается на основе числа документов в
    классе. Поскольку $F_{macro}$ мера игнорирует параметр $TN$, то смещение
    среднего значения будет производиться в сторону того класса, для которого классификатор сработал
    лучше (большее значение $TP$); в тоже время, при использовании $F_{micro}$,
    смещение будет произведено в сторону наибольшего класса. \cite{microMacroMeasures}

    Таким образом, результаты полученные на основе микроусреднения являются мерой
    эффективности на коллекциях большого объема. Для получения аналогичного эффекта
    на коллекциях малого объема, необходимо использовать макроусреднение. \cite{microMacroMeasuresDifferences}

    \subsection{Соревнования в области тональной классификации сообщений}

    % Про коллекции

    Применительно к задачи сентиментального анализа сообщений, в рамках соревнований
    SentiRuEval в качестве классов рассматривают тональную оценку сообщения по
    отношению к рассматриваемым организациям:
    \begin{enumerate}
        \item {\bf Positive} --- положительное сообщение;
        \item {\bf Negative} --- негативное сообщение.
    \end{enumerate}

