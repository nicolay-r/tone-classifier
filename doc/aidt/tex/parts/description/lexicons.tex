\subsection{Построение лексиконов}

Построение лексикона производится на основе {\it меры взаимной информации}
\cite{lexiconSO}:
\begin{gather}
    PMI(t_1, t_2) = log_2 \dfrac{P(t_1\cap t_2)}{P(t_1)\cdot P(t_2)}
    \label{eq:pmi}
\end{gather}

Такая мера показывает связь $t_1$ с $t_2$, т.е. какова вероятность их связи.
В качестве второго аргумента, рассмотрим метку, которая будет соответствовать
одному из тональных классов:
\begin{itemize}
    \item {\it Excellent} -- положительный оттенком;
    \item {\it Poor} -- негативный оттенком.
\end{itemize}

Таким образом, относительно каждого маркера по формуле \ref{eq:pmi} можно
установить степень связи $t_1$ с положительным и негативным оттенком.
На основе разности значений можно определить тональность терма, или его
{\it семантическую ориентацию} (формула \ref{eq:so}).
\begin{equation}
    \label{eq:so}
    SO(t) = PMI(t, Excellent) - PMI(t, Poor)
\end{equation}

От исходной коллекции $K$, на основе которой будет создан лексикон, {\bf требуется
чтобы все сообщения коллекции были размечены по тональным классам}.
Т.е., для каждого сообщения должна быть определена метка {\it Excellent} или
{\it Poor}, которая характеризует тональность сообщения в целом.
Такую метку можно проставить автоматически, и применительно к сообщениям
сети {\it Twitter} на основе {\it эмотиконов} или {\it хэштегов} \cite{severyn}.
В результате лексикон строится следующим образом:
\begin{equation}
    S : \{ \left< t, SO(t) \right> | t \in K\}
\end{equation}

\subsubsection{Составленные лексиконы}
На основе описанного подхода были составлены следующие лексиконы
(параметры представлены в таблице \ref{table:createdLexicons}).
\input{parts/description/tables/lexicons}

$l_1$ -- на основе корпуса сообщений сети {\it Twitter} Ю.~Рубцовой.
Корпус состоит и распространяется в формате двух независимых коллекций
сообщений: {\it positive} и {\it negative}.

$l_2$ -- на основе сообщений сети {\it Twitter}, собранных в течение января {\it 2016} года.
Сообщения сети извлекались с помощью {\it Streaming Twitter API}\footnote{
    Из всего потока принимались только русскоязычные сообщения;
}.
Определение тонального класса каждого из сообщений производилось на
основе содержащихся в нем эмотиконов.

Для этого были составлены два множества эмотиконов (положительные и отрицательные).
Сообщение отмечалось меткой {\it Excellent}, если оно содержало
только эмотиконы положительного множества.
Аналогично в случае, если все эмотиконы сообщения принадлежали
отрицательному множеству, то сообщение отмечалось меткой {\it Poor}.
Сообщение не рассматривалось, если в нем отсутствовали эмотиконы.

В таблице \ref{table:jan_lexicon} приведены примеры наиболее тональных термов
составленного лексикона $l_2$.

\input{parts/description/tables/jan_lexicon}

$l_3$ -- словарь оценочных слов $SentiRuLex$, порожденный
автоматически на основе извлечения информации из нескольких источников,
а затем проверенный вручную экспертами.

Из нескольких источников разных предметных областей были
извлечены списки оценочных слов (и словосочетаний) с проставленными
весами оценочности:
\begin{itemize}
    \item Оценочные слова тезауруса РуТез;
    \item Сленговые слова сети Twitter;
    \item Слова с позитивными или негативными ассоциациями из корпуса новостей.
\end{itemize}
Содержимое списков было сопоставлено с тезаурусом РуТез и все понятия
были извлечены для анализа экспертом.
Эксперт выполнял следующие задачи:
проверка и уточнение тональной оценки слов исходного списка,
уточние оценки значений слова,
и проверка полноту создаваемого словаря (за счет списка синонимов из
близких понятий тезауруса).

Каждая единицa словаря (т.е. слово или словосочетание) состоит из набора
атрибутов, представленного в табл. \ref{table:sentiRuLexItemFormat}.

\input{parts/description/tables/sentiRuLex}

Для построения лексикона были рассмотрены только те единицы словаря,
которые описывали слово (т.е. словосочетания игнорировались).
Из всех атрибутов таблицы \ref{table:sentiRuLexItemFormat} использовались
только {\it лемматизированная форма} и {\it тональность}.
Атрибут тональности преобразовывался в {\it числовую тональность}
(-1 -- negative,
0 -- neutral,
1 -- positive).
Поскольку некоторые слова могут быть представлены
в нескольких различных тональностях, то будем рассматривать только те из них,
тональность которых определена однозначно в рамках всего словаря.

В результате, список пар $\left< \text{лемма, числовая тональность} \right>$
образует результирующий лексикон $l_3$, объем которого составляет $\approx10$ тыс. слов
(см. табл. \ref{table:createdLexicons}).

