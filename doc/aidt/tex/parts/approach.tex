\section{Описание подхода}
    \label{sec:buildingApproachDescription}
    В области классификации сообщений методами машинного обучения, использование
    {\it SVM} классификатора (в сравнении с {\it Naive Bayes}) обусловлено результатами
    тестирования в \cite{svmAdvantages}, которые показывают преимущество SVM на униграммной
    модели обработки сообщений.\footnote{
        Использование униграммной модели упрощает процесс обработки сообщения с
        точки зрения добавления метаинформации, в том числе и на основе лексиконов.
        В текущем подходе все термы, содержащиеся во всех лексиконах, являются
        униграммами.
    }
    Для построения обучающей модели и предсказания
    тональности на ее основе, используется библиотека LibSVM \cite{svmClassifier}.

    \subsection{Обработка сообщений}
    \label{sec:buildingMsgProcessing}
    % Векторизация, ее параметры
    Процесс обработки сообщений коллекции сообщений состоит из следующих этапов:
    \begin{enumerate}
        \item Лемматизация слов сообщений с целью получения списка термов\footnote{
            Использование пакета Yandex Mystem:
            \url{http://tech.yandex.ru/mystem/}
        };

        \item Из сообщения удаляются следующие термы:
            символы <<Ретвита>> (термы со значением <<RT>>),
            имена пользователей сети {\it Twitter} (термы с префиксом <<@>>).
            Таким образом, помимо слов естественных языков в сообщении остаются
            \#хэштеги и {\it URL\hspace{1pt}}-адреса;
        \item Замена некоторых биграмм и униграмм на тональные префиксы.
            Для выполнения этого этапа, используется предварительно составленый
            список пар\footnote{
                [Ссылка на github.]
            }
            $D_{tone} = {\langle t, s\rangle}$, где $t$ -- терм, а $s$ --
            тональная оценка (<<+>> или <<-->>). На этом этапе, для каждого терма $t_i$
            сообщения $m$, такого что $t_i \in D_{tone}$ выполняется замена на соответствующую
            оценку $s$, которая становится префиксом следующего терма $t_{i+1}$.
            Пример преобразования:
            \begin{center}
                \it
                Сейчас \underline{хорошо} работать, \underline{плохо} было раньше.

                Сейчас +работать, -было раньше.
            \end{center}
        \item Для получения весовых коэффициентов термов предполагается
            использовать меру {\it tf-idf}.
    \end{enumerate}

    \subsection{Вспомогательные признаки классификации}
    \label{sec:buildingAdditionalFeatures}
    % В этот раздел вносим признаки, которые добавлялись к основной векторизации
    Помимо термов, составляющих вектор сообщения, предполагается внести
    следующие признаки:
    \begin{itemize}
        \item На основе эмотиконов: предварительно составляются два множества
        эмотиконов (положительные и отрицательные).
        Для каждого множества определяется $C$ -- суммарное число вхождений его
        элементов в рассматриваемое сообщение.
        Результирующий числовой коэффициент вычисляется по формуле: $C_+ - C_-$;

        \item Подсчет количества термов, записанных в ВЕРХНЕМ РЕГИСТРЕ;

        \item Подсчет числа знаков препинания: <<?>>, <<...>>, <<!>>;

        \item Пусть $L$ -- множество составленных лексиконов. Тогда относительно
            каждого лексикона $l_j \in L$ для сообщения $m$, вычисляется:
            \begin{gather}
                \sum\limits_{i=1}^N l_j(t_i), \text{ где } t_i \in m
            \end{gather}
            Если терм $t_i$ отсутствует в лексиконе, то в качестве коэффициента
            рассматривается $l_j(t_i) = 0$.
            Дополнительно выполняется нормализация полученного значения в
            диапазоне $\left[ -1, 1 \right]$ на основе преобразования:
            \begin{numcases}{}
                s = 1 - e^{-|x|}, x > 0  {\label{eq:norm1}}  \\
                s = - (1 - e^{-|x|}), x < 0 {\label{eq:norm2}}
            \end{numcases}
    \end{itemize}
